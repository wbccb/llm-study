<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Transformer | 大模型相关学习电子书</title>
    <meta name="description" content="A VitePress site">
    <meta name="generator" content="VitePress v1.5.0">
    <link rel="preload stylesheet" href="/llm-study/assets/style.DNtqXTzv.css" as="style">
    <link rel="preload stylesheet" href="/llm-study/vp-icons.css" as="style">
    
    <script type="module" src="/llm-study/assets/app.DobkWqeM.js"></script>
    <link rel="preload" href="/llm-study/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/llm-study/assets/chunks/theme.SSXXl_Mi.js">
    <link rel="modulepreload" href="/llm-study/assets/chunks/framework.OqxnQCTf.js">
    <link rel="modulepreload" href="/llm-study/assets/基础原理_深度学习_李宏毅_2023年_2024年_5.Transformer.md.DicLAMbF.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-742e49de><!--[--><!--]--><!--[--><span tabindex="-1" data-v-9f13bb77></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-9f13bb77> Skip to content </a><!--]--><!----><header class="VPNav" data-v-742e49de data-v-91f6d2c4><div class="VPNavBar" data-v-91f6d2c4 data-v-215641af><div class="wrapper" data-v-215641af><div class="container" data-v-215641af><div class="title" data-v-215641af><div class="VPNavBarTitle has-sidebar" data-v-215641af data-v-d4c20f81><a class="title" href="/llm-study/" data-v-d4c20f81><!--[--><!--]--><!----><span data-v-d4c20f81>大模型相关学习电子书</span><!--[--><!--]--></a></div></div><div class="content" data-v-215641af><div class="content-body" data-v-215641af><!--[--><!--]--><div class="VPNavBarSearch search" data-v-215641af><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-215641af data-v-b647a589><span id="main-nav-aria-label" class="visually-hidden" data-v-b647a589> Main Navigation </span><!--[--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="https://github.com/wbccb/llm-study" target="_blank" rel="noreferrer" tabindex="0" data-v-b647a589 data-v-1fb181da><!--[--><span data-v-1fb181da>Home</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-215641af data-v-c70c92e5><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-c70c92e5 data-v-283503e8 data-v-90f5b141><span class="check" data-v-90f5b141><span class="icon" data-v-90f5b141><!--[--><span class="vpi-sun sun" data-v-283503e8></span><span class="vpi-moon moon" data-v-283503e8></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-215641af data-v-a8da1025 data-v-2859b442><!--[--><a class="VPSocialLink no-icon" href="https://github.com/wbccb" aria-label="github" target="_blank" rel="noopener" data-v-2859b442 data-v-b1764eb7><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-215641af data-v-aac53f3a data-v-658bf2d3><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-658bf2d3><span class="vpi-more-horizontal icon" data-v-658bf2d3></span></button><div class="menu" data-v-658bf2d3><div class="VPMenu" data-v-658bf2d3 data-v-4fd58e9a><!----><!--[--><!--[--><!----><div class="group" data-v-aac53f3a><div class="item appearance" data-v-aac53f3a><p class="label" data-v-aac53f3a>Appearance</p><div class="appearance-action" data-v-aac53f3a><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-aac53f3a data-v-283503e8 data-v-90f5b141><span class="check" data-v-90f5b141><span class="icon" data-v-90f5b141><!--[--><span class="vpi-sun sun" data-v-283503e8></span><span class="vpi-moon moon" data-v-283503e8></span><!--]--></span></span></button></div></div></div><div class="group" data-v-aac53f3a><div class="item social-links" data-v-aac53f3a><div class="VPSocialLinks social-links-list" data-v-aac53f3a data-v-2859b442><!--[--><a class="VPSocialLink no-icon" href="https://github.com/wbccb" aria-label="github" target="_blank" rel="noopener" data-v-2859b442 data-v-b1764eb7><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-215641af data-v-00cb0c87><span class="container" data-v-00cb0c87><span class="top" data-v-00cb0c87></span><span class="middle" data-v-00cb0c87></span><span class="bottom" data-v-00cb0c87></span></span></button></div></div></div></div><div class="divider" data-v-215641af><div class="divider-line" data-v-215641af></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-742e49de data-v-0879a5b3><div class="container" data-v-0879a5b3><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-0879a5b3><span class="vpi-align-left menu-icon" data-v-0879a5b3></span><span class="menu-text" data-v-0879a5b3>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-0879a5b3 data-v-f8fe4249><button data-v-f8fe4249>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-742e49de data-v-766c6071><div class="curtain" data-v-766c6071></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-766c6071><span class="visually-hidden" id="sidebar-aria-label" data-v-766c6071> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-274e7dfb><section class="VPSidebarItem level-0" data-v-274e7dfb data-v-75759a6c><div class="item" role="button" tabindex="0" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><h2 class="text" data-v-75759a6c>python</h2><!----></div><div class="items" data-v-75759a6c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/python/1.%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>基础知识</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-274e7dfb><section class="VPSidebarItem level-0" data-v-274e7dfb data-v-75759a6c><div class="item" role="button" tabindex="0" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><h2 class="text" data-v-75759a6c>深度学习</h2><!----></div><div class="items" data-v-75759a6c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>基本概念</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/DeepSeek.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>DeepSeek</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-274e7dfb><section class="VPSidebarItem level-0" data-v-274e7dfb data-v-75759a6c><div class="item" role="button" tabindex="0" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><h2 class="text" data-v-75759a6c>深度学习-李宏毅</h2><!----></div><div class="items" data-v-75759a6c><!--[--><section class="VPSidebarItem level-1" data-v-75759a6c data-v-75759a6c><div class="item" role="button" tabindex="0" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><h3 class="text" data-v-75759a6c>2021年 & 2022年</h3><!----></div><div class="items" data-v-75759a6c><!--[--><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2021%E5%B9%B4&amp;2022%E5%B9%B4/1.%E4%BA%86%E8%A7%A3%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>了解线性模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2021%E5%B9%B4&amp;2022%E5%B9%B4/2.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>机器学习框架</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1" data-v-75759a6c data-v-75759a6c><div class="item" role="button" tabindex="0" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><h3 class="text" data-v-75759a6c>2023年&2024年</h3><!----></div><div class="items" data-v-75759a6c><!--[--><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/1.chatGPT.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>chatGPT</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/2.%E7%94%9F%E6%88%90%E5%BC%8FAI.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>生成式AI</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/3.%E4%B8%8D%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B=%3E%E5%BC%BA%E5%8C%96%E6%A8%A1%E5%9E%8B.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>不训练模型=>强化模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/4.%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%AD%A5%E9%AA%A4.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>训练模型步骤</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/5.Transformer.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>Transformer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/6.%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B&amp;%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>评估模型能力&模型的安全性</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/7.%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>生成策略</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/8.Video%E7%9B%B8%E5%85%B3%E7%9A%84%E7%94%9F%E6%88%90%E5%BC%8FAI%E6%8A%80%E6%9C%AF.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>Video相关的生成式AI技术</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><div class="no-transition group" data-v-274e7dfb><section class="VPSidebarItem level-0" data-v-274e7dfb data-v-75759a6c><div class="item" role="button" tabindex="0" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><h2 class="text" data-v-75759a6c>知识库</h2><!----></div><div class="items" data-v-75759a6c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E7%9F%A5%E8%AF%86%E5%BA%93/NLP+%E5%A4%A7%E6%A8%A1%E5%9E%8B=%3E%E9%97%AE%E7%AD%94.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>NLP+大模型=>问答</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-1" data-v-75759a6c data-v-75759a6c><div class="item" role="button" tabindex="0" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><h3 class="text" data-v-75759a6c>RAGFlow源码分析</h3><!----></div><div class="items" data-v-75759a6c><!--[--><div class="VPSidebarItem level-2 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E7%9F%A5%E8%AF%86%E5%BA%93/RAG/RAGFlow%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/%E6%96%87%E6%A1%A3%E9%A2%84%E5%A4%84%E7%90%86%E9%98%B6%E6%AE%B5/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0&amp;%E8%A7%A3%E6%9E%90%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>文件上传&解析整体流程</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-2" data-v-75759a6c data-v-75759a6c><div class="item" role="button" tabindex="0" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><h4 class="text" data-v-75759a6c>混合检索策略</h4><!----></div><div class="items" data-v-75759a6c><!--[--><div class="VPSidebarItem level-3 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E7%9F%A5%E8%AF%86%E5%BA%93/RAG/RAGFlow%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/%E6%A3%80%E7%B4%A2%E9%98%B6%E6%AE%B5/(WIP)%E6%B7%B7%E5%90%88%E6%A3%80%E7%B4%A2%E7%AD%96%E7%95%A5.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>混合检索策略</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-75759a6c data-v-75759a6c><div class="item" data-v-75759a6c><div class="indicator" data-v-75759a6c></div><a class="VPLink link link" href="/llm-study/%E7%9F%A5%E8%AF%86%E5%BA%93/RAG/RAGFlow%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/%E6%A3%80%E7%B4%A2%E9%98%B6%E6%AE%B5/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%A2%9E%E5%BC%BA%E6%A3%80%E7%B4%A2%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90.html" data-v-75759a6c><!--[--><p class="text" data-v-75759a6c>知识图谱增强检索</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-742e49de data-v-4df68d91><div class="VPDoc has-sidebar has-aside" data-v-4df68d91 data-v-0ed8b67e><!--[--><!--]--><div class="container" data-v-0ed8b67e><div class="aside" data-v-0ed8b67e><div class="aside-curtain" data-v-0ed8b67e></div><div class="aside-container" data-v-0ed8b67e><div class="aside-content" data-v-0ed8b67e><div class="VPDocAside" data-v-0ed8b67e data-v-4d7da887><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-4d7da887 data-v-b577ee35><div class="content" data-v-b577ee35><div class="outline-marker" data-v-b577ee35></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b577ee35>On this page</div><ul class="VPDocOutlineItem root" data-v-b577ee35 data-v-07a964c1><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-4d7da887></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-0ed8b67e><div class="content-container" data-v-0ed8b67e><!--[--><!--]--><main class="main" data-v-0ed8b67e><div style="position:relative;" class="vp-doc _llm-study_%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E6%9D%8E%E5%AE%8F%E6%AF%85_2023%E5%B9%B4&amp;2024%E5%B9%B4_5_Transformer" data-v-0ed8b67e><div><h1 id="transformer" tabindex="-1">Transformer <a class="header-anchor" href="#transformer" aria-label="Permalink to &quot;Transformer&quot;">​</a></h1><ol><li>文字转化为 token</li><li>理解 token：包括语意、位置、上下文 =&gt; 向量</li><li>Transform Block N：多个向量 =&gt;</li><li>Output</li></ol><h2 id="类神经网络技术使用历史" tabindex="-1">类神经网络技术使用历史 <a class="header-anchor" href="#类神经网络技术使用历史" aria-label="Permalink to &quot;类神经网络技术使用历史&quot;">​</a></h2><p><code>N-gram</code> -&gt; <code>Feed-forward Network</code> -&gt; <code>RNN</code> -&gt; <code>Transformer</code></p><h2 id="transformer核心步骤" tabindex="-1">Transformer核心步骤 <a class="header-anchor" href="#transformer核心步骤" aria-label="Permalink to &quot;Transformer核心步骤&quot;">​</a></h2><p><img src="https://github.com/user-attachments/assets/b836b98b-2c5b-4d89-9921-d63e97a85de1" alt="Image"></p><h3 id="根据输入内容生成token" tabindex="-1">根据输入内容生成token <a class="header-anchor" href="#根据输入内容生成token" aria-label="Permalink to &quot;根据输入内容生成token&quot;">​</a></h3><p>每一个大模型都有一个 <code>token list</code>，可以人工生成，也可以通过一定方式生成 <code>token list</code>，但是这些 <code>token list</code>都是大模型自己决定的，并不都相同</p><blockquote><p>可能中文中，每一个字就是一个 <code>token</code> ，在英语中，可能一个单词就是一个 <code>token</code> ，也有可能一个单词就是2个 <code>token</code>，数字也有可能一个单词就是2个 <code>token</code>，比如在 <code>GPT-3.5&amp;GPT-4</code>中，<code>1980</code>可能会被拆为 <code>198</code> 和 <code>0</code> 两个 token</p></blockquote><p><img src="https://github.com/user-attachments/assets/3b62a8b2-b210-4d06-ba7c-55819a157cf1" alt="Image"></p><h3 id="理解每一个token" tabindex="-1">理解每一个token <a class="header-anchor" href="#理解每一个token" aria-label="Permalink to &quot;理解每一个token&quot;">​</a></h3><h3 id="语意" tabindex="-1">语意 <a class="header-anchor" href="#语意" aria-label="Permalink to &quot;语意&quot;">​</a></h3><p>每一个 <code>token</code> 都可以变成 <code>向量</code>，<code>向量</code> 可以得到token之间的关联性和语意，为后面做准备</p><blockquote><p>本质就是通过一个训练好的模型得到对应的向量，但是向量是没考虑上下文的，也就是苹果（苹果手机还是苹果这种水果都是同一个向量）</p></blockquote><p><img src="https://github.com/user-attachments/assets/7f1095a2-c5fe-421f-948e-9a27f507e321" alt="Image"></p><h3 id="位置" tabindex="-1">位置 <a class="header-anchor" href="#位置" aria-label="Permalink to &quot;位置&quot;">​</a></h3><p>可以人工决定规则/训练得到一定的规则，相当于在原来加上语意的基础上 加上 位置的向量，为后面做准备</p><p><img src="https://github.com/user-attachments/assets/f99ceab2-49a0-4b20-9504-6680ae4545a4" alt="Image"></p><h3 id="上下文" tabindex="-1">上下文 <a class="header-anchor" href="#上下文" aria-label="Permalink to &quot;上下文&quot;">​</a></h3><p>根据一定的方式计算出 <code>当前token</code> 与 <code>其它token</code> 的相关性，然后加起来就是 <code>新的向量</code></p><blockquote><p>实际只会考虑 <code>当前token</code> 与 <code>前面的其它token</code> 的相关性</p></blockquote><p><img src="https://github.com/user-attachments/assets/b842bbf9-c946-4fa0-b6fc-e337fa9b46fb" alt="Image"></p><hr><p><img src="https://github.com/user-attachments/assets/2b2a2128-bb5b-4592-8789-bf0a45a08bcf" alt="Image"></p><hr><h3 id="transformer-block" tabindex="-1">Transformer Block <a class="header-anchor" href="#transformer-block" aria-label="Permalink to &quot;Transformer Block&quot;">​</a></h3><p>实际上不会只用一个 <code>Attention</code> _计算出相关性，因为可能有多种相关性！！这些向量是互相独立的</p><p><img src="https://github.com/user-attachments/assets/5dd1f7b2-c743-447c-aa13-8ba6502bfd69" alt="Image"></p><hr><p>最终多个向量需要合并为一个向量</p><p><img src="https://github.com/user-attachments/assets/85b9272b-2333-4408-9992-d6a10867e1bb" alt="Image"></p><p>上面这种流程就是 <code>Transformer Block</code></p><hr><p>但是实际是不止一个 <code>Transformer Block</code>的！</p><p><img src="https://github.com/user-attachments/assets/e8123814-bfc5-4703-947d-490a9b79ee93" alt="Image"></p><hr><h3 id="output" tabindex="-1">Output <a class="header-anchor" href="#output" aria-label="Permalink to &quot;Output&quot;">​</a></h3><p>经过多个 <code>Transformer Block</code> 的转化，最终我们得到一个输出！</p><blockquote><p>下图是一个简化过程，实际还不止下面的流程</p></blockquote><p><img src="https://github.com/user-attachments/assets/ea79342e-f234-4181-bed3-4ed966bf0946" alt="Image"></p><h3 id="其它细节总结" tabindex="-1">其它细节总结 <a class="header-anchor" href="#其它细节总结" aria-label="Permalink to &quot;其它细节总结&quot;">​</a></h3><blockquote><p>为什么我们只需要考虑 <code>当前token</code> 与 <code>前面的其它token</code> 的相关性</p></blockquote><p>因为答案是下图的一个流程，当我们生成 <code>w1</code> 时，下一次我们会将 <code>w1</code> 也作为输入去生成 <code>w2</code>，因此我们只需要考虑 <code>w1</code> 和 <code>它前面的token</code> 的相关性，因为我们后面的token都还没出来</p><blockquote><p>而对于 <code>w1</code> 前面的 token，需不需要计算跟 <code>w1</code> 的相关性呢？</p></blockquote><p>通过实践证明，<code>w1</code> 前面的 token，计不计算跟 <code>w1</code> 的相关性，其实效果都差不多，因此就直接不计算了！</p><p><img src="https://github.com/user-attachments/assets/c6d768b6-32cc-4e4d-b453-591189c94a1c" alt="Image"></p><hr><p>因此一个大模型的出现，总是会强调它能支持多长的 token，那是因为每一个 token 的增加，都需要更大算力的支持！</p><p><img src="https://github.com/user-attachments/assets/940e0898-0bcd-44e8-ae18-0ee2bd55b5b6" alt="Image"></p><h2 id="未来的研究方向-大模型每个流程的内容" tabindex="-1">未来的研究方向-大模型每个流程的内容 <a class="header-anchor" href="#未来的研究方向-大模型每个流程的内容" aria-label="Permalink to &quot;未来的研究方向-大模型每个流程的内容&quot;">​</a></h2><p><img src="https://github.com/user-attachments/assets/f4debcf5-1109-46a1-acec-9a9f4f17d198" alt="Image"></p><h3 id="分析每一个流程" tabindex="-1">分析每一个流程 <a class="header-anchor" href="#分析每一个流程" aria-label="Permalink to &quot;分析每一个流程&quot;">​</a></h3><ol><li>找出影响输出的输入：比如通过屏蔽输入的某一个字去验证对某一个输出的影响</li><li>找出影响输出的训练资料，到底是哪一篇文章或者多篇文章导致目前的输出内容（占比较大的训练资料）</li><li>分析<code>Embedding</code>有什么信息：比如有没有词性？每一个Transformer输出的<code>Embedding</code>到底是什么内容？</li></ol><blockquote><p>目的：当我们了解每一个流程蕴含的信息，我们就可以对这个模型进行底层的优化，加速推理/节省算力等等</p></blockquote><blockquote><p>依赖于将整个训练流程都开源的大模型信息 =&gt; 研究推出论文，不断深化理解复杂流程</p></blockquote><h3 id="直接问大模型" tabindex="-1">直接问大模型 <a class="header-anchor" href="#直接问大模型" aria-label="Permalink to &quot;直接问大模型&quot;">​</a></h3><ol><li>直接问影响输出的训练资料是什么</li><li>直接问得到的输出的信心概率有多少</li><li>直接问每一个输入影响输出的比重</li></ol></div></div></main><footer class="VPDocFooter" data-v-0ed8b67e data-v-fb66563c><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-fb66563c><span class="visually-hidden" id="doc-footer-aria-label" data-v-fb66563c>Pager</span><div class="pager" data-v-fb66563c><!----></div><div class="pager" data-v-fb66563c><a class="VPLink link pager-link next" href="/llm-study/python/1.%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html" data-v-fb66563c><!--[--><span class="desc" data-v-fb66563c>Next page</span><span class="title" data-v-fb66563c>基础知识</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"ai场景_ai_agents_readme.md\":\"CRWSU_WC\",\"ai场景_ai_绘画_stable diffusion_lora.md\":\"B5D_YroA\",\"ai场景_ai_辅助编程_readme.md\":\"C55BNue-\",\"ai场景_知识库_nlp_大模型__问答.md\":\"CQi0zWp_\",\"ai场景_知识库_rag_mineru_readmd.md\":\"OijAGdkG\",\"ai场景_知识库_rag_ragflow源码分析_knowledge.md\":\"DsZJAXL1\",\"ai场景_知识库_rag_ragflow源码分析_readme.md\":\"8TS2L7rb\",\"ai场景_知识库_rag_ragflow源码分析_文档预处理阶段_(todo)文档解析技术.md\":\"f6yrKNco\",\"ai场景_知识库_rag_ragflow源码分析_文档预处理阶段_(todo)构建chunk逻辑详细分析.md\":\"DK1Xuv8g\",\"ai场景_知识库_rag_ragflow源码分析_文档预处理阶段_文件上传_解析整体流程.md\":\"C2JZMLHY\",\"ai场景_知识库_rag_ragflow源码分析_检索阶段_(wip)混合检索策略.md\":\"CrE1lk2s\",\"ai场景_知识库_rag_ragflow源码分析_检索阶段_知识图谱增强检索实现分析.md\":\"CR8oV5cM\",\"ai场景_知识库_rag_ragflow源码分析_生成阶段_生成与交互流程.md\":\"BU1Vu9-8\",\"ai场景_知识库_rag_readme.md\":\"BqQrjFeW\",\"ai场景_知识库_rag_评判标准_评判标准.md\":\"BXSYBvzp\",\"ai场景_知识库_rag_部署方案_硬件选择.md\":\"C634LRoU\",\"ai场景_知识库_rag_部署方案_落地技术选型.md\":\"BGcm99iI\",\"index.md\":\"CqxbQE55\",\"基础原理_ai框架_微调_底层原理_1.langchain.md\":\"C1BTjdYb\",\"基础原理_ai框架_微调_底层原理_2.langgraph.md\":\"NWz4rsiz\",\"基础原理_ai框架_微调_底层原理_3.ai应用开发_微调.md\":\"DnBTqYwT\",\"基础原理_ai框架_微调_底层原理_4.nlp_预训练_微调_ai应用开发.md\":\"BlbRiTeC\",\"基础原理_python_1.基础知识.md\":\"Crq-zIUg\",\"基础原理_python_django框架-5.1_基本概念.md\":\"0l_kP0vZ\",\"基础原理_rag_rag核心基础概念总结.md\":\"DvGVoUrf\",\"基础原理_深度学习_readme.md\":\"TbqtyQQn\",\"基础原理_深度学习_sebastian raschka_1.理解大模型.md\":\"DPZtajAw\",\"基础原理_深度学习_主流大模型原理_deepseek.md\":\"pBQ2s9rY\",\"基础原理_深度学习_基本概念.md\":\"DtaEz28J\",\"基础原理_深度学习_微调_readme.md\":\"0BcZJvKQ\",\"基础原理_深度学习_李宏毅_2021年_2022年_1.了解线性模型.md\":\"oupVjLlq\",\"基础原理_深度学习_李宏毅_2021年_2022年_2.机器学习框架.md\":\"DqRLlpk7\",\"基础原理_深度学习_李宏毅_2023年_2024年_1.chatgpt.md\":\"D5C76o68\",\"基础原理_深度学习_李宏毅_2023年_2024年_2.生成式ai.md\":\"CZTVKBnY\",\"基础原理_深度学习_李宏毅_2023年_2024年_3.不训练模型__强化模型.md\":\"jF0iIGti\",\"基础原理_深度学习_李宏毅_2023年_2024年_4.训练模型步骤.md\":\"Cay363TM\",\"基础原理_深度学习_李宏毅_2023年_2024年_5.transformer.md\":\"DicLAMbF\",\"基础原理_深度学习_李宏毅_2023年_2024年_6.评估模型能力_模型的安全性.md\":\"DEpgr6WW\",\"基础原理_深度学习_李宏毅_2023年_2024年_7.生成策略.md\":\"DMpCQiFc\",\"基础原理_深度学习_李宏毅_2023年_2024年_8.video相关的生成式ai技术.md\":\"DYprjHNz\",\"基础原理_深度学习_李宏毅_readmd.md\":\"CxOHfsoI\",\"实施_运维_readme.md\":\"CXJmmPdb\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"大模型相关学习电子书\",\"description\":\"A VitePress site\",\"base\":\"/llm-study/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"https://github.com/wbccb/llm-study\"}],\"sidebar\":[{\"text\":\"python\",\"items\":[{\"text\":\"基础知识\",\"link\":\"/python/1.基础知识.md\"}]},{\"text\":\"深度学习\",\"items\":[{\"text\":\"基本概念\",\"link\":\"/深度学习/基本概念.md\"},{\"text\":\"DeepSeek\",\"link\":\"/深度学习/主流大模型原理/DeepSeek.md\"}]},{\"text\":\"深度学习-李宏毅\",\"items\":[{\"text\":\"2021年 & 2022年\",\"items\":[{\"text\":\"了解线性模型\",\"link\":\"/深度学习/李宏毅/2021年&2022年/1.了解线性模型.md\"},{\"text\":\"机器学习框架\",\"link\":\"/深度学习/李宏毅/2021年&2022年/2.机器学习框架.md\"}]},{\"text\":\"2023年&2024年\",\"items\":[{\"text\":\"chatGPT\",\"link\":\"/深度学习/李宏毅/2023年&2024年/1.chatGPT.md\"},{\"text\":\"生成式AI\",\"link\":\"/深度学习/李宏毅/2023年&2024年/2.生成式AI.md\"},{\"text\":\"不训练模型=>强化模型\",\"link\":\"/深度学习/李宏毅/2023年&2024年/3.不训练模型=>强化模型.md\"},{\"text\":\"训练模型步骤\",\"link\":\"/深度学习/李宏毅/2023年&2024年/4.训练模型步骤.md\"},{\"text\":\"Transformer\",\"link\":\"/深度学习/李宏毅/2023年&2024年/5.Transformer.md\"},{\"text\":\"评估模型能力&模型的安全性\",\"link\":\"/深度学习/李宏毅/2023年&2024年/6.评估模型能力&模型的安全性.md\"},{\"text\":\"生成策略\",\"link\":\"/深度学习/李宏毅/2023年&2024年/7.生成策略.md\"},{\"text\":\"Video相关的生成式AI技术\",\"link\":\"/深度学习/李宏毅/2023年&2024年/8.Video相关的生成式AI技术.md\"}]}]},{\"text\":\"知识库\",\"items\":[{\"text\":\"NLP+大模型=>问答\",\"link\":\"/知识库/NLP+大模型=>问答.md\"},{\"text\":\"RAGFlow源码分析\",\"items\":[{\"text\":\"文件上传&解析整体流程\",\"link\":\"/知识库/RAG/RAGFlow源码分析/文档预处理阶段/文件上传&解析整体流程.md\"},{\"text\":\"混合检索策略\",\"items\":[{\"text\":\"混合检索策略\",\"link\":\"/知识库/RAG/RAGFlow源码分析/检索阶段/(WIP)混合检索策略.md\"},{\"text\":\"知识图谱增强检索\",\"link\":\"/知识库/RAG/RAGFlow源码分析/检索阶段/知识图谱增强检索实现分析.md\"}]}]}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/wbccb\"}]},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>