<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>DeepSeek | 大模型相关学习电子书</title>
    <meta name="description" content="A VitePress site">
    <meta name="generator" content="VitePress v1.5.0">
    <link rel="preload stylesheet" href="/llm-study/assets/style.D1XloW-X.css" as="style">
    <link rel="preload stylesheet" href="/llm-study/vp-icons.css" as="style">
    
    <script type="module" src="/llm-study/assets/app.C8K0wDnH.js"></script>
    <link rel="preload" href="/llm-study/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/llm-study/assets/chunks/theme.BY3UI_tb.js">
    <link rel="modulepreload" href="/llm-study/assets/chunks/framework.OqxnQCTf.js">
    <link rel="modulepreload" href="/llm-study/assets/docs_深度学习_主流大模型原理_DeepSeek.md.v612l4xq.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-ba1e04ff><!--[--><!--]--><!--[--><span tabindex="-1" data-v-97ea0100></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-97ea0100> Skip to content </a><!--]--><!----><header class="VPNav" data-v-ba1e04ff data-v-b5170f91><div class="VPNavBar" data-v-b5170f91 data-v-c5a70330><div class="wrapper" data-v-c5a70330><div class="container" data-v-c5a70330><div class="title" data-v-c5a70330><div class="VPNavBarTitle has-sidebar" data-v-c5a70330 data-v-c6706323><a class="title" href="/llm-study/" data-v-c6706323><!--[--><!--]--><!----><span data-v-c6706323>大模型相关学习电子书</span><!--[--><!--]--></a></div></div><div class="content" data-v-c5a70330><div class="content-body" data-v-c5a70330><!--[--><!--]--><div class="VPNavBarSearch search" data-v-c5a70330><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-c5a70330 data-v-a30a5015><span id="main-nav-aria-label" class="visually-hidden" data-v-a30a5015> Main Navigation </span><!--[--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="https://github.com/wbccb/llm-study" target="_blank" rel="noreferrer" tabindex="0" data-v-a30a5015 data-v-11bf523d><!--[--><span data-v-11bf523d>Home</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-c5a70330 data-v-6f47f4f1><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6f47f4f1 data-v-94ce7627 data-v-ef45cb02><span class="check" data-v-ef45cb02><span class="icon" data-v-ef45cb02><!--[--><span class="vpi-sun sun" data-v-94ce7627></span><span class="vpi-moon moon" data-v-94ce7627></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-c5a70330 data-v-e81dec13 data-v-14929940><!--[--><a class="VPSocialLink no-icon" href="https://github.com/wbccb" aria-label="github" target="_blank" rel="noopener" data-v-14929940 data-v-75a89838><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-c5a70330 data-v-2cdb8833 data-v-a8d23b86><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-a8d23b86><span class="vpi-more-horizontal icon" data-v-a8d23b86></span></button><div class="menu" data-v-a8d23b86><div class="VPMenu" data-v-a8d23b86 data-v-7cf740b3><!----><!--[--><!--[--><!----><div class="group" data-v-2cdb8833><div class="item appearance" data-v-2cdb8833><p class="label" data-v-2cdb8833>Appearance</p><div class="appearance-action" data-v-2cdb8833><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-2cdb8833 data-v-94ce7627 data-v-ef45cb02><span class="check" data-v-ef45cb02><span class="icon" data-v-ef45cb02><!--[--><span class="vpi-sun sun" data-v-94ce7627></span><span class="vpi-moon moon" data-v-94ce7627></span><!--]--></span></span></button></div></div></div><div class="group" data-v-2cdb8833><div class="item social-links" data-v-2cdb8833><div class="VPSocialLinks social-links-list" data-v-2cdb8833 data-v-14929940><!--[--><a class="VPSocialLink no-icon" href="https://github.com/wbccb" aria-label="github" target="_blank" rel="noopener" data-v-14929940 data-v-75a89838><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-c5a70330 data-v-2f88690c><span class="container" data-v-2f88690c><span class="top" data-v-2f88690c></span><span class="middle" data-v-2f88690c></span><span class="bottom" data-v-2f88690c></span></span></button></div></div></div></div><div class="divider" data-v-c5a70330><div class="divider-line" data-v-c5a70330></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-ba1e04ff data-v-b8c7cf07><div class="container" data-v-b8c7cf07><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-b8c7cf07><span class="vpi-align-left menu-icon" data-v-b8c7cf07></span><span class="menu-text" data-v-b8c7cf07>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-b8c7cf07 data-v-239c32ad><button data-v-239c32ad>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-ba1e04ff data-v-119ab7f8><div class="curtain" data-v-119ab7f8></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-119ab7f8><span class="visually-hidden" id="sidebar-aria-label" data-v-119ab7f8> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-f81fd976><section class="VPSidebarItem level-0" data-v-f81fd976 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h2 class="text" data-v-b849b590>python</h2><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/python/1.%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>基础知识</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-f81fd976><section class="VPSidebarItem level-0 has-active" data-v-f81fd976 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h2 class="text" data-v-b849b590>深度学习</h2><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>基本概念</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/DeepSeek.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>DeepSeek</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-f81fd976><section class="VPSidebarItem level-0" data-v-f81fd976 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h2 class="text" data-v-b849b590>深度学习-李宏毅</h2><!----></div><div class="items" data-v-b849b590><!--[--><section class="VPSidebarItem level-1" data-v-b849b590 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h3 class="text" data-v-b849b590>2021年 & 2022年</h3><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2021%E5%B9%B4&amp;2022%E5%B9%B4/1.%E4%BA%86%E8%A7%A3%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>了解线性模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2021%E5%B9%B4&amp;2022%E5%B9%B4/2.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>机器学习框架</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1" data-v-b849b590 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h3 class="text" data-v-b849b590>2023年&2024年</h3><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/1.chatGPT.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>chatGPT</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/2.%E7%94%9F%E6%88%90%E5%BC%8FAI.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>生成式AI</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/3.%E4%B8%8D%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B=%3E%E5%BC%BA%E5%8C%96%E6%A8%A1%E5%9E%8B.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>不训练模型=>强化模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/4.%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%AD%A5%E9%AA%A4.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>训练模型步骤</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/5.Transformer.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>Transformer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/6.%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B&amp;%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>评估模型能力&模型的安全性</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/7.%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>生成策略</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/8.Video%E7%9B%B8%E5%85%B3%E7%9A%84%E7%94%9F%E6%88%90%E5%BC%8FAI%E6%8A%80%E6%9C%AF.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>Video相关的生成式AI技术</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><div class="no-transition group" data-v-f81fd976><section class="VPSidebarItem level-0" data-v-f81fd976 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h2 class="text" data-v-b849b590>知识库</h2><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E7%9F%A5%E8%AF%86%E5%BA%93/NLP+%E5%A4%A7%E6%A8%A1%E5%9E%8B=%3E%E9%97%AE%E7%AD%94.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>NLP+大模型=>问答</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-ba1e04ff data-v-58605e9b><div class="VPDoc has-sidebar has-aside" data-v-58605e9b data-v-f9254922><!--[--><!--]--><div class="container" data-v-f9254922><div class="aside" data-v-f9254922><div class="aside-curtain" data-v-f9254922></div><div class="aside-container" data-v-f9254922><div class="aside-content" data-v-f9254922><div class="VPDocAside" data-v-f9254922 data-v-da6ed907><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-da6ed907 data-v-d887b119><div class="content" data-v-d887b119><div class="outline-marker" data-v-d887b119></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-d887b119>On this page</div><ul class="VPDocOutlineItem root" data-v-d887b119 data-v-43146e3a><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-da6ed907></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-f9254922><div class="content-container" data-v-f9254922><!--[--><!--]--><main class="main" data-v-f9254922><div style="position:relative;" class="vp-doc _llm-study_docs_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0_%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86_DeepSeek" data-v-f9254922><div><blockquote><p>注：以下内容全部来自<code>DeepSeek-R1</code>和<code>ChatGPT</code>的回答</p></blockquote><h1 id="deepseek" tabindex="-1">DeepSeek <a class="header-anchor" href="#deepseek" aria-label="Permalink to &quot;DeepSeek&quot;">​</a></h1><p>DeepSeek作为基于Transformer架构的大语言模型（LLM），其底层训练原理融合了前沿深度学习技术与工程优化策略，，以下从技术原理与核心优势两个维度进行专业解析</p><h2 id="底层技术原理" tabindex="-1">底层技术原理 <a class="header-anchor" href="#底层技术原理" aria-label="Permalink to &quot;底层技术原理&quot;">​</a></h2><h3 id="_1-模型架构-transformer变体" tabindex="-1">1. 模型架构：Transformer变体 <a class="header-anchor" href="#_1-模型架构-transformer变体" aria-label="Permalink to &quot;1. 模型架构：Transformer变体&quot;">​</a></h3><ul><li>自注意力机制（Self-Attention）：通过计算词元间的关联权重（QKV矩阵），动态捕捉长距离依赖关系，解决RNN的序列建模瓶颈</li><li>位置编码（Positional Encoding）：注入序列位置信息（如旋转位置编码RoPE），弥补Transformer对顺序不敏感的缺陷</li><li>前馈网络（FFN）：多层感知机（MLP）对注意力输出进行非线性变换，增强模型表达能力</li></ul><h3 id="_2-预训练目标-自监督学习" tabindex="-1">2. 预训练目标：自监督学习 <a class="header-anchor" href="#_2-预训练目标-自监督学习" aria-label="Permalink to &quot;2. 预训练目标：自监督学习&quot;">​</a></h3><ul><li>掩码语言建模（MLM）：随机遮蔽输入序列的部分词元（如15%比例），通过交叉熵损失函数监督模型还原原始文本</li><li>大规模语料：训练数据涵盖多领域文本（网页、书籍、代码等），通过数据清洗与去噪构建高质量语料库</li></ul><h3 id="_3-优化策略" tabindex="-1">3. 优化策略 <a class="header-anchor" href="#_3-优化策略" aria-label="Permalink to &quot;3. 优化策略&quot;">​</a></h3><ul><li>混合精度训练：FP16/FP32混合计算加速训练，结合梯度缩放避免数值下溢</li><li>分布式并行：采用数据并行（ZeRO优化）、流水线并行（PipeDream）与张量并行（Megatron-LM）实现千卡级高效训练</li><li>动态批处理（Dynamic Batching）：根据序列长度动态调整批次大小，提升GPU利用率</li></ul><h3 id="_4-规模化训练-scaling-laws" tabindex="-1">4. 规模化训练（Scaling Laws） <a class="header-anchor" href="#_4-规模化训练-scaling-laws" aria-label="Permalink to &quot;4. 规模化训练（Scaling Laws）&quot;">​</a></h3><ul><li>模型参数量扩展：遵循Chinchilla定律，平衡模型规模（N）、数据量（D）与计算量（C），追求最优性价比（N∝D^0.5）</li><li>课程学习（Curriculum Learning）：分阶段调整训练数据难度（如从短文本到长文档），提升收敛效率</li></ul><h2 id="核心优势" tabindex="-1">核心优势 <a class="header-anchor" href="#核心优势" aria-label="Permalink to &quot;核心优势&quot;">​</a></h2><h3 id="_1-高效上下文建模" tabindex="-1">1. 高效上下文建模 <a class="header-anchor" href="#_1-高效上下文建模" aria-label="Permalink to &quot;1. 高效上下文建模&quot;">​</a></h3><ul><li>稀疏注意力（Sparse Attention）：通过局部窗口或哈希分块降低计算复杂度（O(N²)→O(N logN)），支持更长上下文（如128K tokens）</li><li>KV Cache优化：推理时缓存历史Key-Value状态，减少重复计算，提升生成速度</li></ul><h3 id="_2-泛化与迁移能力" tabindex="-1">2. 泛化与迁移能力 <a class="header-anchor" href="#_2-泛化与迁移能力" aria-label="Permalink to &quot;2. 泛化与迁移能力&quot;">​</a></h3><ul><li>多任务统一架构：通过提示工程（Prompt Engineering）适配下游任务，无需针对特定任务调整模型结构</li><li>指令微调（Instruction Tuning）：基于人工标注指令数据对齐模型输出与人类意图，提升零样本（Zero-Shot）泛化性</li></ul><h3 id="_3-工程优化优势" tabindex="-1">3. 工程优化优势 <a class="header-anchor" href="#_3-工程优化优势" aria-label="Permalink to &quot;3. 工程优化优势&quot;">​</a></h3><ul><li>FlashAttention算法：利用GPU显存层次结构优化注意力计算，实现3-5倍训练加速</li><li>MoE（Mixture of Experts）架构：动态路由至子网络（如DeepSeek-MoE），以较低计算成本扩展模型容量</li></ul><h3 id="_4-生态兼容性" tabindex="-1">4. 生态兼容性 <a class="header-anchor" href="#_4-生态兼容性" aria-label="Permalink to &quot;4. 生态兼容性&quot;">​</a></h3><ul><li>开源框架支持：兼容PyTorch、DeepSpeed等生态工具链，支持低秩适配（LoRA）等轻量化微调方案</li><li>硬件适配优化：针对NVLink互联GPU集群与国产算力卡（如昇腾）定制内核，提升训练吞吐量</li></ul><h3 id="技术对比与突破" tabindex="-1">技术对比与突破 <a class="header-anchor" href="#技术对比与突破" aria-label="Permalink to &quot;技术对比与突破&quot;">​</a></h3><p>相较于传统BERT/GPT架构，DeepSeek通过以下创新实现性能跃迁：</p><ul><li>长上下文优化：采用RoPE+NTK-Aware插值，突破Transformer的上下文长度外推瓶颈</li><li>训练稳定性：集成LayerNorm与残差连接的梯度路径优化，缓解万卡规模训练的梯度震荡问题</li><li>数据效率提升：基于语义去重与质量评分的数据筛选策略，使单位数据的信息密度提升30%+</li></ul><h2 id="论文剖析" tabindex="-1">论文剖析 <a class="header-anchor" href="#论文剖析" aria-label="Permalink to &quot;论文剖析&quot;">​</a></h2><p>DeepSeek-R1最新发表的论文《DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning》是在DeepSeek-V3-Base基础上进一步经过强化学习（RL）和多阶段微调得到的。其底层架构仍然继承了DeepSeek系列一贯的混合专家设计（DeepSeekMoE），在此基础上进行了多项创新与优化</p><h3 id="强化学习" tabindex="-1">强化学习 <a class="header-anchor" href="#强化学习" aria-label="Permalink to &quot;强化学习&quot;">​</a></h3><p>强化学习（Reinforcement Learning，简称RL）是一种机器学习范式，其核心思想是让一个智能体（agent）通过与环境（environment）的不断交互，基于获得的奖励（reward）和惩罚信号来学习如何采取行动，从而在长期内最大化累计回报（return）。这种学习过程类似于人类或动物在试错中逐步改进行为的方式</p><h3 id="混合专家模型简介" tabindex="-1">混合专家模型简介 <a class="header-anchor" href="#混合专家模型简介" aria-label="Permalink to &quot;混合专家模型简介&quot;">​</a></h3><p>混合专家模型是一种旨在提高模型容量和计算效率的架构。其核心思想是将整个模型划分为多个“专家”子网络，以及一个用于路由的门控网络。具体来说，当输入数据进入模型时，门控网络会根据当前任务或输入特征选择性地激活其中的少数几个专家，而不是让所有参数全部参与计算。 这种“稀疏激活”的设计有以下几个主要优点：</p><ul><li><p><strong>参数规模大但计算高效</strong></p><p>虽然模型的总参数量可能非常巨大，但每个输入仅激活其中的一小部分，从而在不增加计算成本的前提下提高模型容量。</p></li><li><p><strong>降低计算和内存开销</strong></p><p>通过只计算相关专家的输出，可以显著减少前向和反向传播时的计算量与内存使用。</p></li><li><p><strong>灵活性与扩展性</strong></p><p>MoE架构允许不同专家专注于不同的任务或特征，使得模型在面对复杂问题时能够更好地进行分工合作，从而提升整体性能。</p></li></ul><p>这种架构目前已经被广泛应用于大型语言模型和多模态模型中，为进一步降低训练与推理成本提供了可能性</p><h3 id="deepseek-r1论文解读与混合专家模型创新" tabindex="-1">DeepSeek-R1论文解读与混合专家模型创新 <a class="header-anchor" href="#deepseek-r1论文解读与混合专家模型创新" aria-label="Permalink to &quot;DeepSeek-R1论文解读与混合专家模型创新&quot;">​</a></h3><p>DeepSeek-R1在继承DeepSeek系列一贯的混合专家架构基础上，通过细粒度专家划分、共享专家策略以及高效的动态路由机制，实现了如下创新与优势：</p><ul><li>参数高效利用与稀疏激活：每个token只激活少数专家，大幅降低计算和内存开销。</li><li>动态路由与负载均衡：确保各专家均衡参与，有效提升训练与推理效率。</li><li>强化学习驱动的推理能力：无需大量监督数据，利用 <code>RL（强化学习）</code> 促使模型自主提升推理表现，达到与先进模型相近的水平。</li><li>成本低、扩展性好：节省硬件资源的同时，通过模型蒸馏还可以迁移到小模型上，便于在各种应用场景中部署。</li></ul></div></div></main><footer class="VPDocFooter" data-v-f9254922 data-v-3a03286c><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-3a03286c><span class="visually-hidden" id="doc-footer-aria-label" data-v-3a03286c>Pager</span><div class="pager" data-v-3a03286c><a class="VPLink link pager-link prev" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html" data-v-3a03286c><!--[--><span class="desc" data-v-3a03286c>Previous page</span><span class="title" data-v-3a03286c>基本概念</span><!--]--></a></div><div class="pager" data-v-3a03286c><a class="VPLink link pager-link next" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2021%E5%B9%B4&amp;2022%E5%B9%B4/1.%E4%BA%86%E8%A7%A3%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html" data-v-3a03286c><!--[--><span class="desc" data-v-3a03286c>Next page</span><span class="title" data-v-3a03286c>了解线性模型</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"docs_python_1.基础知识.md\":\"Bg_tur2v\",\"docs_python_django框架-5.1_基本概念.md\":\"BUdNc-pt\",\"docs_深度学习_readme.md\":\"EsTASKxp\",\"docs_深度学习_sebastian raschka_1.理解大模型.md\":\"Sxw863VH\",\"docs_深度学习_主流大模型原理_deepseek.md\":\"v612l4xq\",\"docs_深度学习_基本概念.md\":\"CBDmzcye\",\"docs_深度学习_李宏毅_2021年_2022年_1.了解线性模型.md\":\"DMySFK1b\",\"docs_深度学习_李宏毅_2021年_2022年_2.机器学习框架.md\":\"DFt5zSjd\",\"docs_深度学习_李宏毅_2023年_2024年_1.chatgpt.md\":\"C1lsTu7H\",\"docs_深度学习_李宏毅_2023年_2024年_2.生成式ai.md\":\"CwmcMwtE\",\"docs_深度学习_李宏毅_2023年_2024年_3.不训练模型__强化模型.md\":\"DtZn0AnH\",\"docs_深度学习_李宏毅_2023年_2024年_4.训练模型步骤.md\":\"CJmMQZv3\",\"docs_深度学习_李宏毅_2023年_2024年_5.transformer.md\":\"DYa_PQr0\",\"docs_深度学习_李宏毅_2023年_2024年_6.评估模型能力_模型的安全性.md\":\"B-SkLoX0\",\"docs_深度学习_李宏毅_2023年_2024年_7.生成策略.md\":\"BEWQm0al\",\"docs_深度学习_李宏毅_2023年_2024年_8.video相关的生成式ai技术.md\":\"CdTS_AJ_\",\"docs_深度学习_李宏毅_readmd.md\":\"CSmrZeEY\",\"docs_知识库_nlp_大模型__问答.md\":\"Dnug9v_J\",\"index.md\":\"BhNUKPKk\",\"readme.md\":\"DvvCb5zT\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"大模型相关学习电子书\",\"description\":\"A VitePress site\",\"base\":\"/llm-study/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"https://github.com/wbccb/llm-study\"}],\"sidebar\":[{\"text\":\"python\",\"items\":[{\"text\":\"基础知识\",\"link\":\"/docs/python/1.基础知识.md\"}]},{\"text\":\"深度学习\",\"items\":[{\"text\":\"基本概念\",\"link\":\"/docs/深度学习/基本概念.md\"},{\"text\":\"DeepSeek\",\"link\":\"/docs/深度学习/主流大模型原理/DeepSeek.md\"}]},{\"text\":\"深度学习-李宏毅\",\"items\":[{\"text\":\"2021年 & 2022年\",\"items\":[{\"text\":\"了解线性模型\",\"link\":\"docs/深度学习/李宏毅/2021年&2022年/1.了解线性模型.md\"},{\"text\":\"机器学习框架\",\"link\":\"docs/深度学习/李宏毅/2021年&2022年/2.机器学习框架.md\"}]},{\"text\":\"2023年&2024年\",\"items\":[{\"text\":\"chatGPT\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/1.chatGPT.md\"},{\"text\":\"生成式AI\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/2.生成式AI.md\"},{\"text\":\"不训练模型=>强化模型\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/3.不训练模型=>强化模型.md\"},{\"text\":\"训练模型步骤\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/4.训练模型步骤.md\"},{\"text\":\"Transformer\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/5.Transformer.md\"},{\"text\":\"评估模型能力&模型的安全性\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/6.评估模型能力&模型的安全性.md\"},{\"text\":\"生成策略\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/7.生成策略.md\"},{\"text\":\"Video相关的生成式AI技术\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/8.Video相关的生成式AI技术.md\"}]}]},{\"text\":\"知识库\",\"items\":[{\"text\":\"NLP+大模型=>问答\",\"link\":\"docs/知识库/NLP+大模型=>问答.md\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/wbccb\"}]},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>