# 基本概念


## 知识蒸馏

知识蒸馏通常用于 `大模型` -> `小模型`

1. 定义：让轻量级学生模型模仿教师模型的输出分布，实现模型压缩或者性能迁移
2. 典型场景：将GPT-4级别的模型压缩为更小参数的版本，或者适配特定硬件（如移动端）


## 大模型时代的迁移学习技术

预训练-微调范式（Pretraining-Finetuning）

核心流程：
- 预训练阶段：在大规模通用数据（如互联网文本）上训练基础模型（如BERT、GPT）。
- 微调阶段：在特定任务数据（如医疗问答）上更新部分参数，适配下游任务。

典型应用：
- 文本分类：BERT微调后用于新闻主题识别。
- 代码生成：Codex基于GPT-3在代码数据上微调


## 多模态大模型

多模态大模型是指能够同时处理和理解多种数据模态（如文本、图像、音频、视频、传感器数据等）的大规模深度学习模型

其核心是通过统一架构（如Transformer）实现跨模态信息的对齐、融合与推理，从而模仿人类多感官协同认知的能力。

典型代表包括
- CLIP（OpenAI）：对齐图像与文本的跨模态表示。
- DALL-E：根据文本生成高质量图像。
- Flamingo（DeepMind）：融合文本与视频的对话模型

## 强化学习

强化学习（Reinforcement Learning，简称RL）是一种机器学习范式，其核心思想是让一个智能体（agent）通过与环境（environment）的不断交互，基于获得的奖励（reward）和惩罚信号来学习如何采取行动，从而在长期内最大化累计回报（return）。这种学习过程类似于人类或动物在试错中逐步改进行为的方式
