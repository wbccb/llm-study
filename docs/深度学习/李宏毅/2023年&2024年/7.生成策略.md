# 生成式人工智慧

机器产生复杂（几乎无法穷举）有结构（由有限的基本单位构成）的物件

- 文字：文字由 `token` 组成，每一个大模型训练前都会形成一定数量的 token，比如 `Llmam 2` 由 `32k` 个不同的 token
- 图片：图片由 `pixel像素` 组成，`8 BPP`->  256个颜色；`16 BPP`->  65536个颜色；`24 BPP`->  1670万个颜色
- 声音：声音由 `取样点Sample` 组成，有多少个数据取决于 `取样解析度`

主要分为两种策略：
- Autoregressive Generation
- Non-Autoregressive Generation


## Autoregressive Generation

- 优点：生成质量高，适合文字类的生成
- 缺点：需要按部就班，一个一个输出生成（包括图片像素和声音取样点），对于要生成大规模数据的物件，速度非常慢

![Image](https://github.com/user-attachments/assets/878d556f-07d8-47eb-a2cc-b3a43cefaffc)


## Non-Autoregressive Generation

- 优点：生成速度快
- 缺点：生成质量低

![Image](https://github.com/user-attachments/assets/eafb704f-f613-4f3d-bdb1-a6cbcdae91be)

> 但是使用 Autoregressive Generation 进行图片和声音生成实在太慢了，有什么办法改进 Non-Autoregressive Generation 速度吗？

## 图片和声音生成的策略

### Autoregressive Generation + Non-Autoregressive Generation 结合

![Image](https://github.com/user-attachments/assets/003fb4e8-edc3-4ffd-949e-ac22f1760b4a)

> 那么 Autoregressive Generation + Non-Autoregressive Generation 是如何进行训练的呢？

![Image](https://github.com/user-attachments/assets/a0c039fa-a04a-427f-86e0-f40d10a2eb83)


### Non-Autoregressive Generation 多次生成

本质可以看作一次 Autoregressive Generation，但是需要的次数大大减少

![Image](https://github.com/user-attachments/assets/6af39e98-64a0-4342-a373-0371ac8fd852)

------

![Image](https://github.com/user-attachments/assets/18cc557f-94a3-4da4-8a40-0bde27bb01f0)

------

甚至我们使用 Non-Autoregressive Generation 多次生成可以模仿 `Autoregressive Generation + Non-Autoregressive Generation 结合`的模式，先生成一个压缩的版本（很小），然后最终再放大形成一个大的图片数据

![Image](https://github.com/user-attachments/assets/0d357e7f-93d3-4edd-b43d-9c49fe44833d)