# Transformer

1. 文字转化为 token
2. 理解 token：包括语意、位置、上下文 => 向量
3. Transform Block N：多个向量 =>
4. Output

## 类神经网络技术使用历史

`N-gram` -> `Feed-forward Network` -> `RNN` -> `Transformer`


## Transformer核心步骤

![Image](https://github.com/user-attachments/assets/b836b98b-2c5b-4d89-9921-d63e97a85de1)


### 根据输入内容生成token
每一个大模型都有一个 `token list`，可以人工生成，也可以通过一定方式生成 `token list`，但是这些  `token list`都是大模型自己决定的，并不都相同

> 可能中文中，每一个字就是一个 `token` ，在英语中，可能一个单词就是一个 `token` ，也有可能一个单词就是2个 `token`，数字也有可能一个单词就是2个 `token`，比如在 `GPT-3.5&GPT-4`中，`1980`可能会被拆为 `198` 和 `0` 两个 token

![Image](https://github.com/user-attachments/assets/3b62a8b2-b210-4d06-ba7c-55819a157cf1)


### 理解每一个token

### 语意

每一个 `token` 都可以变成 `向量`，`向量` 可以得到token之间的关联性和语意，为后面做准备

> 本质就是通过一个训练好的模型得到对应的向量，但是向量是没考虑上下文的，也就是苹果（苹果手机还是苹果这种水果都是同一个向量）

![Image](https://github.com/user-attachments/assets/7f1095a2-c5fe-421f-948e-9a27f507e321)


### 位置

可以人工决定规则/训练得到一定的规则，相当于在原来加上语意的基础上 加上 位置的向量，为后面做准备

![Image](https://github.com/user-attachments/assets/f99ceab2-49a0-4b20-9504-6680ae4545a4)

### 上下文

根据一定的方式计算出 `当前token` 与 `其它token` 的相关性，然后加起来就是 `新的向量`

> 实际只会考虑 `当前token` 与 `前面的其它token` 的相关性

![Image](https://github.com/user-attachments/assets/b842bbf9-c946-4fa0-b6fc-e337fa9b46fb)

-----

![Image](https://github.com/user-attachments/assets/2b2a2128-bb5b-4592-8789-bf0a45a08bcf)

------

### Transformer Block

实际上不会只用一个 `Attention` _计算出相关性，因为可能有多种相关性！！这些向量是互相独立的

![Image](https://github.com/user-attachments/assets/5dd1f7b2-c743-447c-aa13-8ba6502bfd69)

-----------

最终多个向量需要合并为一个向量

![Image](https://github.com/user-attachments/assets/85b9272b-2333-4408-9992-d6a10867e1bb)

上面这种流程就是 `Transformer Block`

-----------


但是实际是不止一个 `Transformer Block`的！

![Image](https://github.com/user-attachments/assets/e8123814-bfc5-4703-947d-490a9b79ee93)

-----------

### Output

经过多个 `Transformer Block` 的转化，最终我们得到一个输出！

> 下图是一个简化过程，实际还不止下面的流程

![Image](https://github.com/user-attachments/assets/ea79342e-f234-4181-bed3-4ed966bf0946)


### 其它细节总结

> 为什么我们只需要考虑 `当前token` 与 `前面的其它token` 的相关性

因为答案是下图的一个流程，当我们生成 `w1` 时，下一次我们会将  `w1` 也作为输入去生成 `w2`，因此我们只需要考虑 `w1` 和 `它前面的token` 的相关性，因为我们后面的token都还没出来

> 而对于 `w1` 前面的 token，需不需要计算跟 `w1` 的相关性呢？

通过实践证明，`w1` 前面的 token，计不计算跟 `w1` 的相关性，其实效果都差不多，因此就直接不计算了！

![Image](https://github.com/user-attachments/assets/c6d768b6-32cc-4e4d-b453-591189c94a1c)

-----------

因此一个大模型的出现，总是会强调它能支持多长的 token，那是因为每一个 token 的增加，都需要更大算力的支持！

![Image](https://github.com/user-attachments/assets/940e0898-0bcd-44e8-ae18-0ee2bd55b5b6)


## 未来的研究方向-大模型每个流程的内容

![Image](https://github.com/user-attachments/assets/f4debcf5-1109-46a1-acec-9a9f4f17d198)

### 分析每一个流程
1. 找出影响输出的输入：比如通过屏蔽输入的某一个字去验证对某一个输出的影响
2. 找出影响输出的训练资料，到底是哪一篇文章或者多篇文章导致目前的输出内容（占比较大的训练资料）
3. 分析`Embedding`有什么信息：比如有没有词性？每一个Transformer输出的`Embedding`到底是什么内容？

> 目的：当我们了解每一个流程蕴含的信息，我们就可以对这个模型进行底层的优化，加速推理/节省算力等等

> 依赖于将整个训练流程都开源的大模型信息 => 研究推出论文，不断深化理解复杂流程

### 直接问大模型

1. 直接问影响输出的训练资料是什么
2. 直接问得到的输出的信心概率有多少
3. 直接问每一个输入影响输出的比重

