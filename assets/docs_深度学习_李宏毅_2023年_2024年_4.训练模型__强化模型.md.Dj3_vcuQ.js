import{_ as a,c as t,a0 as o,o as c}from"./chunks/framework.OqxnQCTf.js";const b=JSON.parse('{"title":"训练模型=>强化模型","description":"","frontmatter":{},"headers":[],"relativePath":"docs/深度学习/李宏毅/2023年&2024年/4.训练模型=>强化模型.md","filePath":"docs/深度学习/李宏毅/2023年&2024年/4.训练模型=>强化模型.md"}'),d={name:"docs/深度学习/李宏毅/2023年&2024年/4.训练模型=>强化模型.md"};function l(s,e,r,i,p,h){return c(),t("div",null,e[0]||(e[0]=[o('<h1 id="训练模型-强化模型" tabindex="-1">训练模型=&gt;强化模型 <a class="header-anchor" href="#训练模型-强化模型" aria-label="Permalink to &quot;训练模型=&gt;强化模型&quot;">​</a></h1><h2 id="找参数的挑战" tabindex="-1">找参数的挑战 <a class="header-anchor" href="#找参数的挑战" aria-label="Permalink to &quot;找参数的挑战&quot;">​</a></h2><h3 id="训练失败" tabindex="-1">训练失败 <a class="header-anchor" href="#训练失败" aria-label="Permalink to &quot;训练失败&quot;">​</a></h3><p>使用<code>一组超参数</code> + <code>训练资料</code> 去训练一个 <code>函数</code>，然后通过 <code>函数</code> 去验证测试数据是否符合预期来判断这个<code>函数</code>是否正确</p><p>并不是每次训练都能得到正确的 <code>函数</code>，因此需要算力！不断进行训练</p><blockquote><p>所谓的调参数，其实就是调 <code>超参数</code>，因为最终得到的 <code>函数</code> 的参数太多了，根本不知道哪里有问题，因此每次都是换一组<code>超参数</code> 去训练</p></blockquote><p><img src="https://github.com/user-attachments/assets/c2e73344-149a-4874-b76b-62d2e402f3d9" alt="Image"></p><h3 id="训练成果-但是测试失败-代入新的数据失败" tabindex="-1">训练成果，但是测试失败（代入新的数据失败） <a class="header-anchor" href="#训练成果-但是测试失败-代入新的数据失败" aria-label="Permalink to &quot;训练成果，但是测试失败（代入新的数据失败）&quot;">​</a></h3><p>可能训练出来的 <code>函数</code>（模型）只是根据颜色去区分动物...因此这个 <code>函数</code> 还是失败的</p><p><img src="https://github.com/user-attachments/assets/0341e57b-6dbe-45df-aff1-f9df167435a3" alt="Image"></p><h3 id="优化训练结果的方法" tabindex="-1">优化训练结果的方法 <a class="header-anchor" href="#优化训练结果的方法" aria-label="Permalink to &quot;优化训练结果的方法&quot;">​</a></h3><ul><li>增加训练资料的多样性</li><li>调整超参数</li><li>设置正确的初始参数（本质随机设置）</li></ul><blockquote><p>那如何才能获取比较合适的初始参数呢？请看下面的分析</p></blockquote><h2 id="训练的主要步骤" tabindex="-1">训练的主要步骤 <a class="header-anchor" href="#训练的主要步骤" aria-label="Permalink to &quot;训练的主要步骤&quot;">​</a></h2><ol><li>阶段1：【自督导式学习】不需要太多人工介入获取训练资料的方式，从网络上获取大量资料进行自我训练</li><li>阶段2：【督导式学习】耗费大量人力=&gt;资料标注，使用阶段1得到的参数作为 `原始参数</li></ol><blockquote><p>为了避免阶段2得到的参数跟阶段1参数过于不同，可以使用一些小技巧<code>Adapter</code>在阶段1参数的基础上增加一些少量参数，使得两个阶段得到的参数相差不大！</p></blockquote><p><img src="https://github.com/user-attachments/assets/84f8f622-f813-4136-a3c9-3f6bceb7adc1" alt="Image"></p><blockquote><p>在阶段2分为两条路线：打造一堆专才（使用特定领域的人工资料训练出解决特定领域的问题，比如翻译）+ 通才（使用多种多样的标注资料，涵盖多种领域）</p></blockquote><hr><p>目前新的大模型的产生方式：</p><ol><li>利用开源的力量，拿到阶段1的参数作为阶段2的初始参数，直接省略预训练过程</li><li>使用其它大模型（比如ChatGPT得到一些类似人工标注的资料：有输入和输出）的数据进行微调</li></ol><p><img src="https://github.com/user-attachments/assets/46dec504-38c8-461d-b9c2-ed5b13b874ff" alt="Image"></p><hr><ol start="3"><li>阶段3：【增强式学习】通过收集人类的反馈，进行参数的调整（提高正确答案的概率，降低错误答案的概率）</li></ol><p><img src="https://github.com/user-attachments/assets/9b6c8102-c563-4811-a86f-615526eee034" alt="Image"></p><blockquote><p>但是人工是非常贵的，专门给你反馈的数量还是很少的，有没有什么方法模仿人工反馈呢？</p></blockquote><p>大模型直接向 <code>回馈模型</code> 进行学习（先要训练一个<code>回馈模型</code>）</p><blockquote><p>过度向 <code>虚拟人类</code> 学习会导致准确率降低，因此目前在开发新的模式改进 <code>回馈模型</code> 进行学习的模式，但是还不成熟，比如用其它模型来评价你的模型产出，或者用同一个模型来评价你的模型产出</p></blockquote><p><img src="https://github.com/user-attachments/assets/e499fb34-ab04-4c23-a250-f41e208e34ee" alt="Image"></p><hr><p>【增强式学习】的难题：可以解决问题但是会伤害其他人的反馈 / 人类都无法判断对错的反馈 =&gt; 会导致整个模型走向极端</p><hr><p>注：<code>BERT</code> 模型预训练后，学习一种语言，可以同时举一反三，学会其它语言</p>',33)]))}const n=a(d,[["render",l]]);export{b as __pageData,n as default};
