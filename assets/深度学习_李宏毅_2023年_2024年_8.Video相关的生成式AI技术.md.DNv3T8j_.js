import{_ as e,c as t,a0 as s,o}from"./chunks/framework.OqxnQCTf.js";const b=JSON.parse('{"title":"Video相关的生成式AI技术","description":"","frontmatter":{},"headers":[],"relativePath":"深度学习/李宏毅/2023年&2024年/8.Video相关的生成式AI技术.md","filePath":"深度学习/李宏毅/2023年&2024年/8.Video相关的生成式AI技术.md"}'),i={name:"深度学习/李宏毅/2023年&2024年/8.Video相关的生成式AI技术.md"};function r(c,a,d,h,n,l){return o(),t("div",null,a[0]||(a[0]=[s('<h1 id="video相关的生成式ai技术" tabindex="-1">Video相关的生成式AI技术 <a class="header-anchor" href="#video相关的生成式ai技术" aria-label="Permalink to &quot;Video相关的生成式AI技术&quot;">​</a></h1><h2 id="文字生成video的挑战" tabindex="-1">文字生成video的挑战 <a class="header-anchor" href="#文字生成video的挑战" aria-label="Permalink to &quot;文字生成video的挑战&quot;">​</a></h2><p><img src="https://github.com/user-attachments/assets/781b3296-03c6-4572-8c7d-1f3e56a0f2fd" alt="Image"></p><h3 id="优化方向-减少attention的计算" tabindex="-1">优化方向：减少attention的计算 <a class="header-anchor" href="#优化方向-减少attention的计算" aria-label="Permalink to &quot;优化方向：减少attention的计算&quot;">​</a></h3><p>从3D-&gt; 2D + 1D的模式 <img src="https://github.com/user-attachments/assets/00cd41b2-2beb-40b6-a5d7-83ea00636538" alt="Image"></p><h3 id="优化方向-多次生成" tabindex="-1">优化方向：多次生成 <a class="header-anchor" href="#优化方向-多次生成" aria-label="Permalink to &quot;优化方向：多次生成&quot;">​</a></h3><p><img src="https://github.com/user-attachments/assets/979bd854-c63a-4cde-96ca-d5618d8f6482" alt="Image"></p><h2 id="常用的文字生成video技术" tabindex="-1">常用的文字生成video技术 <a class="header-anchor" href="#常用的文字生成video技术" aria-label="Permalink to &quot;常用的文字生成video技术&quot;">​</a></h2><h3 id="vae、flow-based-技术" tabindex="-1">VAE、Flow-based 技术 <a class="header-anchor" href="#vae、flow-based-技术" aria-label="Permalink to &quot;VAE、Flow-based 技术&quot;">​</a></h3><p>我们可以同时进行 <code>资讯抽取模型</code> 和 <code>图片生成模型</code> 的训练，比对的结果就是一开始输入的图片和最终输出图片的差异</p><p>通过 <code>资讯抽取模型</code> ，我们可以得到更多的信息，辅助 <code>图片生成模型</code> 更加精准生成图片</p><p><img src="https://github.com/user-attachments/assets/38e403b5-5e4e-4eb1-8467-8563c0814f57" alt="Image"></p><hr><p><img src="https://github.com/user-attachments/assets/3347c0dc-5c48-4546-a6cd-886c5f57b630" alt="Image"></p><p>这些 <code>noise</code> 也不是一个无用的东西，我们可以使用这些 <code>noise</code> 进行图片的调整</p><p><img src="https://github.com/user-attachments/assets/bd9bc711-c3dd-4087-9c03-3ebd5b03e704" alt="Image"></p><h2 id="diffusion" tabindex="-1">Diffusion <a class="header-anchor" href="#diffusion" aria-label="Permalink to &quot;Diffusion&quot;">​</a></h2><p><img src="https://github.com/user-attachments/assets/9633f76b-25d6-4544-8cc0-0444c88a7077" alt="Image"></p><h3 id="训练方式" tabindex="-1">训练方式 <a class="header-anchor" href="#训练方式" aria-label="Permalink to &quot;训练方式&quot;">​</a></h3><p>自己可以不停加 noise，然后训练出对应的 Decoder（可以Denoise出马赛克还原图片）</p><p><img src="https://github.com/user-attachments/assets/b2ffc769-9360-4cc7-8b90-3b8287e3ed67" alt="Image"></p><h3 id="diffusion-transformer结合" tabindex="-1">Diffusion + Transformer结合 <a class="header-anchor" href="#diffusion-transformer结合" aria-label="Permalink to &quot;Diffusion + Transformer结合&quot;">​</a></h3><p><img src="https://github.com/user-attachments/assets/b4480695-d8a0-4f54-a95e-f343f8d4aa86" alt="Image"></p><h2 id="gan" tabindex="-1">GAN <a class="header-anchor" href="#gan" aria-label="Permalink to &quot;GAN&quot;">​</a></h2><p>使用反馈机制去调整参数</p><p><img src="https://github.com/user-attachments/assets/8d68bb96-6cc8-4abb-9b9a-34f5d978804c" alt="Image"></p><h2 id="gan与其它方法结合" tabindex="-1">GAN与其它方法结合 <a class="header-anchor" href="#gan与其它方法结合" aria-label="Permalink to &quot;GAN与其它方法结合&quot;">​</a></h2><p><img src="https://github.com/user-attachments/assets/551a2f7b-36c6-43f1-9031-5db2587825b2" alt="Image"></p>',28)]))}const u=e(i,[["render",r]]);export{b as __pageData,u as default};
