import{_ as a,c as s,a0 as l,o as n}from"./chunks/framework.OqxnQCTf.js";const e="/llm-study/assets/image1.Du9PF_zl.svg",t="/llm-study/assets/img.TcBEYvlE.png",p="/llm-study/assets/img_1.C-Xx8IcV.png",E=JSON.parse('{"title":"Local_Pdf_Chat_RAG","description":"","frontmatter":{},"headers":[],"relativePath":"projects/MiniRAG/READMD.md","filePath":"projects/MiniRAG/READMD.md"}'),r={name:"projects/MiniRAG/READMD.md"};function h(o,i,k,d,c,u){return n(),s("div",null,i[0]||(i[0]=[l('<h1 id="local-pdf-chat-rag" tabindex="-1">Local_Pdf_Chat_RAG <a class="header-anchor" href="#local-pdf-chat-rag" aria-label="Permalink to &quot;Local_Pdf_Chat_RAG&quot;">​</a></h1><p>参照 <a href="https://github.com/weiwill88/Local_Pdf_Chat_RAG" target="_blank" rel="noreferrer">https://github.com/weiwill88/Local_Pdf_Chat_RAG</a> 进行动手实践RAG整套流程的搭建，旨在学习RAG的基础知识，从而更好地理解主流开源RAG库代码的精髓以及进行二次开发</p><p><img src="'+e+'" alt="image.svg"></p><h2 id="chroma-db" tabindex="-1">Chroma DB <a class="header-anchor" href="#chroma-db" aria-label="Permalink to &quot;Chroma DB&quot;">​</a></h2><p>Chroma DB 是一个开源的向量数据库（Vector Database），专门设计用于存储、检索和管理向量嵌入（Embeddings）。它是为机器学习和人工智能应用（如自然语言处理、图像处理等）量身定制的，能够高效地处理高维向量数据</p><p><strong>适用场景</strong></p><ul><li>语义搜索：基于文本嵌入的语义相似性搜索。</li><li>推荐系统：通过向量相似性为用户推荐内容。</li><li>图像检索：基于图像嵌入的相似图像搜索。</li><li>问答系统：基于嵌入的问答和知识检索。</li><li>聚类和分类：对高维向量数据进行聚类或分类</li></ul><p><img src="'+t+'" alt="img.png"></p><h2 id="all-minilm-l6-v2" tabindex="-1">all-MiniLM-L6-v2 <a class="header-anchor" href="#all-minilm-l6-v2" aria-label="Permalink to &quot;all-MiniLM-L6-v2&quot;">​</a></h2><p>all-MiniLM-L6-v2 是一个基于 Transformer 架构的轻量级语言模型，专门用于生成高质量的文本嵌入（Text Embeddings）。它是由 Microsoft 团队开发的，属于 MiniLM 系列模型之一，旨在提供高效且性能优异的文本表示能力，适用于各种自然语言处理（NLP）任务（如语义搜索、文本分类、聚类、问答系统等）</p><p><img src="'+p+`" alt="img_1.png"></p><h2 id="bm25" tabindex="-1">BM25 <a class="header-anchor" href="#bm25" aria-label="Permalink to &quot;BM25&quot;">​</a></h2><p>BM25（Best Match 25）是一种经典的信息检索算法，用于衡量文档与查询之间的相关性。它是 TF-IDF（Term Frequency-Inverse Document Frequency）的改进版本，旨在更准确地评估文档在给定查询下的匹配程度。BM25 是搜索引擎和全文检索系统中广泛使用的算法之一</p><p>BM25 的核心思想是通过以下两个因素来评估文档的相关性：</p><ul><li>词频（Term Frequency, TF）：查询中的词在文档中出现的频率。</li><li>逆文档频率（Inverse Document Frequency, IDF）：查询中的词在整个文档集合中的稀有程度。 BM25 在 TF-IDF 的基础上引入了文档长度归一化，以解决长文档可能包含更多无关词汇的问题。</li></ul><p>适用场景</p><ul><li>搜索引擎：用于网页、文档等全文检索。</li><li>问答系统：基于关键词匹配的问答检索。</li><li>推荐系统：通过关键词匹配推荐相关内容。</li></ul><p>示例代码：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> rank_bm25 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> BM25Okapi</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 文档集合</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;The cat sat on the mat.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;The dog played in the yard.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;Cats and dogs are pets.&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 分词</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenized_docs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [doc.split() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> doc </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> documents]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化 BM25</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bm25 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> BM25Okapi(tokenized_docs)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查询</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;cat dog&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenized_query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> query.split()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 计算得分</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">scores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> bm25.get_scores(tokenized_query)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(scores)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回最相关的文档</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">best_doc_index </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scores.argmax()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Best document:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, documents[best_doc_index])</span></span></code></pre></div><h2 id="jieba" tabindex="-1">jieba <a class="header-anchor" href="#jieba" aria-label="Permalink to &quot;jieba&quot;">​</a></h2><p>jieba 是一个流行的 Python 中文分词库，专门用于将中文文本切分成词语（即分词）。它是中文自然语言处理（NLP）任务中常用的工具之一，具有高效、易用和功能丰富的特点</p><p><strong>适用场景</strong></p><ul><li>中文文本预处理：用于机器学习或深度学习的文本数据预处理。</li><li>搜索引擎：构建中文搜索引擎的分词模块。</li><li>文本分析：如情感分析、主题建模等。</li><li>信息提取：如关键词提取、实体识别等。</li></ul><h2 id="langchain" tabindex="-1">LangChain <a class="header-anchor" href="#langchain" aria-label="Permalink to &quot;LangChain&quot;">​</a></h2><p>LangChain 是一个用于构建基于 语言模型（LLM，Large Language Models） 的应用程序的框架。它旨在简化与语言模型的交互，并支持构建复杂的、功能丰富的应用，如问答系统、聊天机器人、文档分析工具等。LangChain 提供了模块化的组件和工具，使开发者能够轻松地将语言模型与其他数据源、工具和逻辑集成在一起</p><h3 id="langchain-text-splitter" tabindex="-1">langchain.text_splitter <a class="header-anchor" href="#langchain-text-splitter" aria-label="Permalink to &quot;langchain.text_splitter&quot;">​</a></h3><p>langchain.text_splitter 是 LangChain 库中的一个模块，专门用于将文本分割成更小的块（chunks）</p><p>langchain.text_splitter 提供了多种文本分割器，可以根据不同的需求将文本分割成块。常见的分割方式包括：</p><ul><li>按字符分割：将文本按固定字符数分割。</li><li>按句子分割：将文本按句子边界分割。</li><li>按段落分割：将文本按段落分割。</li><li>按标记（Token）分割：将文本按模型的标记（Token）数分割（适合用于语言模型输入）。</li><li>递归分割：结合多种分割方式，递归地将文本分割成更小的块</li></ul><h2 id="serpapi搜索" tabindex="-1">SerpAPI搜索 <a class="header-anchor" href="#serpapi搜索" aria-label="Permalink to &quot;SerpAPI搜索&quot;">​</a></h2><p>SerpAPI 搜索是一种基于 API 的搜索引擎结果获取服务，专为开发者设计，能够通过编程接口从主流搜索引擎（如 Google、Bing 等）中高效获取结构化数据</p><ol><li>支持 Google、Bing、Yahoo 等多个搜索引擎，开发者可通过参数 engine 快速切换，例如指定 &quot;engine&quot;: &quot;bing&quot; 调用必应搜索</li><li>提供一致的 JSON 格式返回结果，简化数据解析流程</li><li>支持地理位置（gl）、语言（hl）等参数调整，例如 &quot;gl&quot;: &quot;us&quot; 指定美国地区、&quot;hl&quot;: &quot;en&quot; 设置英语界面 + 可自定义搜索类型（如网页、图片、新闻），满足不同业务需求</li><li>通过 Python 的 SerpAPIWrapper 工具库快速调用 API，仅需 3-5 行代码即可完成搜索功能</li></ol><h2 id="mrkl-agent" tabindex="-1">MRKL Agent <a class="header-anchor" href="#mrkl-agent" aria-label="Permalink to &quot;MRKL Agent&quot;">​</a></h2><ul><li>MRKL: 模块化推理、知识和语言系统</li><li>Agent是大模型(LLM)</li></ul><p>MRKL Agent就是会使用工具的大模型</p><h2 id="知识图谱" tabindex="-1">知识图谱 <a class="header-anchor" href="#知识图谱" aria-label="Permalink to &quot;知识图谱&quot;">​</a></h2><p>在知识图谱中，实体是构成语义网络的核心节点，通过“实体-关系-实体”三元组构建结构化知识（如&lt;曹操，儿子，曹丕&gt;）。两者的区别在于：</p><ul><li>实体是单一对象或概念的抽象；</li><li>知识图谱是实体及其关系的集合，强调关联性与推理能力</li></ul><blockquote><p>知识图谱的概念最早由谷歌于2012年提出，旨在提升搜索引擎对用户意图的理解能力，例如搜索“玛丽·居里”时直接展示其生平、成就及关联人物，而非仅提供网页链接</p></blockquote><h3 id="知识构建" tabindex="-1">知识构建 <a class="header-anchor" href="#知识构建" aria-label="Permalink to &quot;知识构建&quot;">​</a></h3><ol><li>数据采集与清洗：从结构化数据库（如CRM系统）、非结构化文档（如产品手册、工单记录）及网络资源中提取原始数据。例如，电商客服系统需整合商品属性（价格、库存）、用户评价、退换货政策等</li><li>实体关系抽取：例如在金融场景中，通过依存句法分析提取“企业-法人-股权比例”三元组</li><li>知识存储与更新：采用图数据库（Neo4j、Nebula Graph）存储三元组，并建立索引加速查询</li></ol><h3 id="问题解析" tabindex="-1">问题解析 <a class="header-anchor" href="#问题解析" aria-label="Permalink to &quot;问题解析&quot;">​</a></h3><p><strong>1. 意图识别与实体链接</strong></p><p>通过语义分析确定用户问题类型（如咨询、投诉）并链接到图谱实体。例如用户问“如何重置路由器密码”，系统识别意图为“设备操作指南”，并定位实体“路由器”</p><p><strong>2. 多跳推理路径生成</strong></p><p>对复杂问题分解子查询。例如用户问“周杰伦的专辑中有哪些歌曲获得过金曲奖？”，流程如下：</p><ul><li>子查询1：检索「周杰伦-创作-专辑」关系 → 得到专辑列表</li><li>子查询2：遍历各专辑的「歌曲-获奖-金曲奖」路径 → 筛选结果。</li></ul><h3 id="语义推理" tabindex="-1">语义推理 <a class="header-anchor" href="#语义推理" aria-label="Permalink to &quot;语义推理&quot;">​</a></h3><p><strong>1. 基于规则的推理</strong></p><p>应用预定义逻辑处理特定场景</p><blockquote><p>例如，用户问“订单未到货能否退款？”，系统根据图谱中「订单状态-物流状态-退款政策」链条判断：若物流显示“运输中”则建议等待；若显示“丢失”则触发退款流程</p></blockquote><p><strong>2. 图嵌入推理</strong></p><p>利用TransE等算法预测隐含关系</p><blockquote><p>例如客服系统发现用户多次询问“手机发热”，自动关联图谱中的“电池型号-散热设计缺陷”历史工单，提示可能存在的产品批次问题</p></blockquote><h3 id="答案生成" tabindex="-1">答案生成 <a class="header-anchor" href="#答案生成" aria-label="Permalink to &quot;答案生成&quot;">​</a></h3><p><strong>1. 结构化答案抽取</strong></p><p>直接返回图谱中的属性值</p><blockquote><p>例如用户问“华为P60的屏幕尺寸”，系统查询「华为P60-屏幕尺寸-6.7英寸」并生成答案</p></blockquote><p><strong>2. 自然语言生成</strong></p><p>结合模板与LLM生成多模态回复</p><blockquote><p>例如用户问“如何解决打印机卡纸”，系统调用图谱中的「故障原因-解决步骤」数据，通过GPT-4生成带步骤图示的回复</p></blockquote><p><strong>3. 多轮对话管理</strong></p><p>记录上下文并动态扩展查询</p><blockquote><p>例如用户追问“刚才说的路由器密码重置对AX3000型号有效吗？”，系统基于对话历史锁定具体产品型号，校验知识图谱中的兼容性信息</p></blockquote><h2 id="语义-意图" tabindex="-1">语义 &amp; 意图 <a class="header-anchor" href="#语义-意图" aria-label="Permalink to &quot;语义 &amp; 意图&quot;">​</a></h2><h3 id="意图数据构建" tabindex="-1">意图数据构建 <a class="header-anchor" href="#意图数据构建" aria-label="Permalink to &quot;意图数据构建&quot;">​</a></h3><ol><li>人工构建基础框架：</li></ol><ul><li>业务规则定义：人工根据企业服务场景定义意图分类，例如电商场景中的“退货申请”“物流查询”“商品咨询”等</li><li>知识库标注：对历史对话数据进行人工标注，例如将“如何退款？”标注为“退款流程”意图，为后续模型训练提供基准数据</li></ul><ol start="2"><li>机器学习模型自动化扩展</li></ol><ul><li>监督学习：利用标注数据训练分类模型（如BERT、SVM），通过语义相似度匹配新问题与已知意图。例如，用户输入“快递到哪了？”会被自动归类到“物流查询”意图</li><li>无监督学习：通过聚类算法（如K-means）发现未标注数据中的潜在意图类别，辅助人工扩展意图库</li></ul><ol start="3"><li>大语言模型（LLM）增强</li></ol><ul><li>意图生成：利用GPT-4等模型自动分析用户问题，生成可能的意图标签（如将“手机充不进电”映射到“设备故障报修”意图）</li><li>意图泛化：通过提示工程（Prompt Engineering）让模型理解意图的变体表达，例如“我想取消订单”和“订单不要了”均对应“订单取消”意图</li></ul><h3 id="意图含义" tabindex="-1">意图含义 <a class="header-anchor" href="#意图含义" aria-label="Permalink to &quot;意图含义&quot;">​</a></h3><ul><li>意图（Intent）：指用户通过自然语言表达的需求或目的</li><li>意图识别：将用户的自然语言输入（如“查话费”或“如何更改套餐”）分类为预定义的任务类别</li></ul><blockquote><p>例如，在电信场景中，用户提问“我的流量用完了”会被识别为“流量查询”或“套餐升级”意图</p></blockquote><h3 id="意图技术实现" tabindex="-1">意图技术实现 <a class="header-anchor" href="#意图技术实现" aria-label="Permalink to &quot;意图技术实现&quot;">​</a></h3><ul><li>基于规则的系统：依赖关键词匹配（如“查话费”直接触发余额查询），适合简单场景但灵活性差。</li><li>机器学习模型：如支持向量机（SVM）、随机森林，通过标注数据训练模型，支持多意图识别。</li><li>深度学习模型：如BERT、GPT，利用上下文理解处理复杂语义，例如同时识别“查话费并改套餐”中的多意图</li></ul><h3 id="语义训练过程" tabindex="-1">语义训练过程 <a class="header-anchor" href="#语义训练过程" aria-label="Permalink to &quot;语义训练过程&quot;">​</a></h3><ol><li>构建实体、关系、意图的数据</li><li>自然语言处理（NLP）模型训练</li></ol><ul><li>意图识别与实体抽取：利用BERT、LSTM等模型，通过标注数据训练模型自动识别用户问题中的意图和关键实体（如时间、地点）</li><li>语义相似度计算：通过词向量模型（如Word2Vec）或句向量模型（如Sentence-BERT），匹配用户问题与知识库答案的语义相关性</li></ul><ol start="3"><li>动态知识融合与更新</li></ol><ul><li>知识图谱自动化扩展：从非结构化文本（如工单记录、产品手册）中抽取新实体关系，例如通过依存句法分析发现“iPhone 15支持Type-C充电”等新知识</li><li>在线学习优化：根据用户反馈实时调整模型，例如将误判的“换货”问题重新归类至正确意图</li></ul><ol start="4"><li>多模态语义整合</li></ol><ul><li>语音与图像处理：结合ASR（语音转文本）和OCR（图片识别）技术，将语音提问、故障截图转化为文本信息，再通过NLP解析语义</li><li>情感分析增强：基于用户语气或表情符号（如愤怒表情）调整应答策略，提升服务个性化</li></ul><blockquote><p>本质就是不断训练：可以通过用户输入=&gt;解析的语义去匹配正确的 实体 + 意图 （实体-关系-属性）</p></blockquote><h3 id="语义含义" tabindex="-1">语义含义 <a class="header-anchor" href="#语义含义" aria-label="Permalink to &quot;语义含义&quot;">​</a></h3><p>语义是指用户输入的自然语言背后隐含的意图、上下文关系及深层含义，而非单纯的文字表面信息。</p><p>其核心是通过对语言结构的分析，将用户问题转化为机器可理解的逻辑表达，并实现精准的应答匹配</p><ul><li>意图识别：理解用户问题的根本需求</li><li>上下文：捕捉对话中的历史信息</li><li>情感和歧义处：识别用户情绪以及消除多义词的干扰</li></ul><h3 id="语义技术实现" tabindex="-1">语义技术实现 <a class="header-anchor" href="#语义技术实现" aria-label="Permalink to &quot;语义技术实现&quot;">​</a></h3><ul><li>自然语言处理（NLP）：利用BERT等预训练模型进行分词、句法分析，生成文本向量表示；</li><li>知识图谱：构建实体关系网络（如“产品-故障-解决方案”），支持语义推理；</li><li>深度学习算法：通过LSTM、Transformer模型捕捉长距离语义依赖</li></ul><h2 id="cross-encoder-交叉编码器" tabindex="-1">Cross-Encoder（交叉编码器） <a class="header-anchor" href="#cross-encoder-交叉编码器" aria-label="Permalink to &quot;Cross-Encoder（交叉编码器）&quot;">​</a></h2><p>Cross-Encoder通过联合语义建模和动态交互，解决了传统检索模型的信息丢失与静态表征问题，成为RAG系统中提升精度的关键组件。尽管其计算成本较高，但通过两阶段架构（Bi-Encoder召回+Cross-Encoder精排），可平衡效率与效果。未来，随着模型压缩技术与硬件加速的发展，Cross-Encoder有望在实时场景中发挥更大作用</p><p><strong>1. 联合编码机制</strong></p><p>Cross-Encoder将查询（Query）与文档（Document）拼接为一个整体输入模型（如BERT），通过Transformer层进行双向注意力交互。例如，对查询“机器学习应用”和文档“深度学习在医疗影像中的实践”，模型会同时分析两者所有Token之间的关系，输出一个0-1的相关性分数。</p><p><strong>2. 动态语义建模</strong></p><p>与Bi-Encoder（双编码器）的静态向量不同，Cross-Encoder根据具体查询动态调整文档的语义表征。例如，当查询为“苹果公司市值”时，文档中“苹果手机销量”的权重会被强化，而“苹果水果种植”则被弱化。</p><p><strong>3. 端到端相关性评分</strong></p><p>模型通过分类层直接输出相关性得分，而非通过向量相似度计算。这种端到端的设计能捕捉复杂的语义匹配模式，如逻辑推理、上下文依赖等</p>`,99)]))}const q=a(r,[["render",h]]);export{E as __pageData,q as default};
