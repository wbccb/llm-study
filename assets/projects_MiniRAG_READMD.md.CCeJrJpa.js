import{_ as i,c as a,a0 as n,o as l}from"./chunks/framework.OqxnQCTf.js";const t="/llm-study/assets/image1.Du9PF_zl.svg",e="/llm-study/assets/img.TcBEYvlE.png",p="/llm-study/assets/img_1.C-Xx8IcV.png",u=JSON.parse('{"title":"Local_Pdf_Chat_RAG","description":"","frontmatter":{},"headers":[],"relativePath":"projects/MiniRAG/READMD.md","filePath":"projects/MiniRAG/READMD.md"}'),h={name:"projects/MiniRAG/READMD.md"};function r(k,s,o,d,c,E){return l(),a("div",null,s[0]||(s[0]=[n('<h1 id="local-pdf-chat-rag" tabindex="-1">Local_Pdf_Chat_RAG <a class="header-anchor" href="#local-pdf-chat-rag" aria-label="Permalink to &quot;Local_Pdf_Chat_RAG&quot;">​</a></h1><p>参照 <a href="https://github.com/weiwill88/Local_Pdf_Chat_RAG" target="_blank" rel="noreferrer">https://github.com/weiwill88/Local_Pdf_Chat_RAG</a> 进行动手实践RAG整套流程的搭建，旨在学习RAG的基础知识，从而更好地理解主流开源RAG库代码的精髓以及进行二次开发</p><p><img src="'+t+'" alt="image.svg"></p><h2 id="chroma-db" tabindex="-1">Chroma DB <a class="header-anchor" href="#chroma-db" aria-label="Permalink to &quot;Chroma DB&quot;">​</a></h2><p>Chroma DB 是一个开源的向量数据库（Vector Database），专门设计用于存储、检索和管理向量嵌入（Embeddings）。它是为机器学习和人工智能应用（如自然语言处理、图像处理等）量身定制的，能够高效地处理高维向量数据</p><p><strong>适用场景</strong></p><ul><li>语义搜索：基于文本嵌入的语义相似性搜索。</li><li>推荐系统：通过向量相似性为用户推荐内容。</li><li>图像检索：基于图像嵌入的相似图像搜索。</li><li>问答系统：基于嵌入的问答和知识检索。</li><li>聚类和分类：对高维向量数据进行聚类或分类</li></ul><p><img src="'+e+'" alt="img.png"></p><h2 id="all-minilm-l6-v2" tabindex="-1">all-MiniLM-L6-v2 <a class="header-anchor" href="#all-minilm-l6-v2" aria-label="Permalink to &quot;all-MiniLM-L6-v2&quot;">​</a></h2><p>all-MiniLM-L6-v2 是一个基于 Transformer 架构的轻量级语言模型，专门用于生成高质量的文本嵌入（Text Embeddings）。它是由 Microsoft 团队开发的，属于 MiniLM 系列模型之一，旨在提供高效且性能优异的文本表示能力，适用于各种自然语言处理（NLP）任务（如语义搜索、文本分类、聚类、问答系统等）</p><p><img src="'+p+`" alt="img_1.png"></p><h2 id="bm25" tabindex="-1">BM25 <a class="header-anchor" href="#bm25" aria-label="Permalink to &quot;BM25&quot;">​</a></h2><p>BM25（Best Match 25）是一种经典的信息检索算法，用于衡量文档与查询之间的相关性。它是 TF-IDF（Term Frequency-Inverse Document Frequency）的改进版本，旨在更准确地评估文档在给定查询下的匹配程度。BM25 是搜索引擎和全文检索系统中广泛使用的算法之一</p><p>BM25 的核心思想是通过以下两个因素来评估文档的相关性：</p><ul><li>词频（Term Frequency, TF）：查询中的词在文档中出现的频率。</li><li>逆文档频率（Inverse Document Frequency, IDF）：查询中的词在整个文档集合中的稀有程度。 BM25 在 TF-IDF 的基础上引入了文档长度归一化，以解决长文档可能包含更多无关词汇的问题。</li></ul><p>适用场景</p><ul><li>搜索引擎：用于网页、文档等全文检索。</li><li>问答系统：基于关键词匹配的问答检索。</li><li>推荐系统：通过关键词匹配推荐相关内容。</li></ul><p>示例代码：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> rank_bm25 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> BM25Okapi</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 文档集合</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;The cat sat on the mat.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;The dog played in the yard.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;Cats and dogs are pets.&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 分词</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenized_docs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [doc.split() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> doc </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> documents]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化 BM25</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bm25 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> BM25Okapi(tokenized_docs)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查询</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;cat dog&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenized_query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> query.split()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 计算得分</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">scores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> bm25.get_scores(tokenized_query)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(scores)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回最相关的文档</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">best_doc_index </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scores.argmax()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Best document:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, documents[best_doc_index])</span></span></code></pre></div><h2 id="jieba" tabindex="-1">jieba <a class="header-anchor" href="#jieba" aria-label="Permalink to &quot;jieba&quot;">​</a></h2><p>jieba 是一个流行的 Python 中文分词库，专门用于将中文文本切分成词语（即分词）。它是中文自然语言处理（NLP）任务中常用的工具之一，具有高效、易用和功能丰富的特点</p><p><strong>适用场景</strong></p><ul><li>中文文本预处理：用于机器学习或深度学习的文本数据预处理。</li><li>搜索引擎：构建中文搜索引擎的分词模块。</li><li>文本分析：如情感分析、主题建模等。</li><li>信息提取：如关键词提取、实体识别等。</li></ul><h2 id="langchain" tabindex="-1">LangChain <a class="header-anchor" href="#langchain" aria-label="Permalink to &quot;LangChain&quot;">​</a></h2><p>LangChain 是一个用于构建基于 语言模型（LLM，Large Language Models） 的应用程序的框架。它旨在简化与语言模型的交互，并支持构建复杂的、功能丰富的应用，如问答系统、聊天机器人、文档分析工具等。LangChain 提供了模块化的组件和工具，使开发者能够轻松地将语言模型与其他数据源、工具和逻辑集成在一起</p><h3 id="langchain-text-splitter" tabindex="-1">langchain.text_splitter <a class="header-anchor" href="#langchain-text-splitter" aria-label="Permalink to &quot;langchain.text_splitter&quot;">​</a></h3><p>langchain.text_splitter 是 LangChain 库中的一个模块，专门用于将文本分割成更小的块（chunks）</p><p>langchain.text_splitter 提供了多种文本分割器，可以根据不同的需求将文本分割成块。常见的分割方式包括：</p><ul><li>按字符分割：将文本按固定字符数分割。</li><li>按句子分割：将文本按句子边界分割。</li><li>按段落分割：将文本按段落分割。</li><li>按标记（Token）分割：将文本按模型的标记（Token）数分割（适合用于语言模型输入）。</li><li>递归分割：结合多种分割方式，递归地将文本分割成更小的块</li></ul>`,29)]))}const y=i(h,[["render",r]]);export{u as __pageData,y as default};
