import{_ as a,c as l,a0 as r,o as t}from"./chunks/framework.OqxnQCTf.js";const p=JSON.parse('{"title":"内容","description":"","frontmatter":{},"headers":[],"relativePath":"基础原理/AI框架&微调&底层原理/4.NLP&预训练&微调&AI应用开发.md","filePath":"基础原理/AI框架&微调&底层原理/4.NLP&预训练&微调&AI应用开发.md"}'),o={name:"基础原理/AI框架&微调&底层原理/4.NLP&预训练&微调&AI应用开发.md"};function i(n,e,c,d,s,h){return t(),l("div",null,e[0]||(e[0]=[r('<h1 id="内容" tabindex="-1">内容 <a class="header-anchor" href="#内容" aria-label="Permalink to &quot;内容&quot;">​</a></h1><ol><li>前言 本项目的缘起、背景及读者建议</li><li>第一章 NLP 基础概念 什么是 NLP、发展历程、任务分类、文本表示演进</li><li>第二章 Transformer 架构 注意力机制、Encoder-Decoder、手把手搭建 Transformer</li><li>第三章 预训练语言模型 Encoder-only、Encoder-Decoder、Decoder-Only 模型对比</li><li>第四章 大语言模型 LLM 定义、训练策略、涌现能力分析</li><li>第五章 动手搭建大模型 实现 LLaMA2、训练 Tokenizer、预训练小型 LLM</li><li>第六章 大模型训练实践 预训练、有监督微调、LoRA/QLoRA 高效微调</li><li>第七章 大模型应用 模型评测、RAG 检索增强、Agent 智能体</li><li>Extra Chapter LLM Blog 优秀的大模型 学习笔记/Blog</li></ol><h1 id="参考" tabindex="-1">参考 <a class="header-anchor" href="#参考" aria-label="Permalink to &quot;参考&quot;">​</a></h1><ol><li><a href="https://datawhalechina.github.io/happy-llm/#/" target="_blank" rel="noreferrer">https://datawhalechina.github.io/happy-llm/#/</a></li></ol>',4)]))}const L=a(o,[["render",i]]);export{p as __pageData,L as default};
