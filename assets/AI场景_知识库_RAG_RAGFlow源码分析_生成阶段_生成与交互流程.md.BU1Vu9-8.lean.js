import{_ as i,c as a,a0 as n,o as l}from"./chunks/framework.OqxnQCTf.js";const E=JSON.parse('{"title":"生成与交互流程","description":"","frontmatter":{},"headers":[],"relativePath":"AI场景/知识库/RAG/RAGFlow源码分析/生成阶段/生成与交互流程.md","filePath":"AI场景/知识库/RAG/RAGFlow源码分析/生成阶段/生成与交互流程.md"}'),t={name:"AI场景/知识库/RAG/RAGFlow源码分析/生成阶段/生成与交互流程.md"};function e(h,s,p,k,r,o){return l(),a("div",null,s[0]||(s[0]=[n(`<h1 id="生成与交互流程" tabindex="-1">生成与交互流程 <a class="header-anchor" href="#生成与交互流程" aria-label="Permalink to &quot;生成与交互流程&quot;">​</a></h1><p>代码路径：<code>rag/generation/</code></p><h2 id="_1-llm-集成架构" tabindex="-1">1.LLM 集成架构 <a class="header-anchor" href="#_1-llm-集成架构" aria-label="Permalink to &quot;1.LLM 集成架构&quot;">​</a></h2><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># api/llm_routing.py 核心逻辑</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> generate_answer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(query, contexts):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    prompt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> build_prompt(query, contexts)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    response </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> llm_client.generate(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">config.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">MODEL_NAME</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        prompt</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">prompt,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        temperature</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        max_tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> format_response(response, contexts)</span></span></code></pre></div><h2 id="_2-引用溯源机制" tabindex="-1">2.引用溯源机制 <a class="header-anchor" href="#_2-引用溯源机制" aria-label="Permalink to &quot;2.引用溯源机制&quot;">​</a></h2><ul><li>分块指纹匹配（MD5 + 位置元数据）</li><li>可视化高亮显示（web/ 前端实现）</li><li>置信度打分（通过 rag/verification 模块）</li></ul><h2 id="_3-异常处理" tabindex="-1">3.异常处理 <a class="header-anchor" href="#_3-异常处理" aria-label="Permalink to &quot;3.异常处理&quot;">​</a></h2><ul><li>检索失败降级策略（关键词扩展/同义词替换）</li><li>LLM 超时重试机制（configs/llm_timeout）</li><li>敏感信息过滤（基于 SECURITY.md 规则）</li></ul>`,8)]))}const c=i(t,[["render",e]]);export{E as __pageData,c as default};
