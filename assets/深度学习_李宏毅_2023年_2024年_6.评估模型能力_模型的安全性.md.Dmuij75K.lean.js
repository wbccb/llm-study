import{_ as e,c as l,a0 as t,o as i}from"./chunks/framework.OqxnQCTf.js";const p=JSON.parse('{"title":"评估模型的能力","description":"","frontmatter":{"outline":[1,6]},"headers":[],"relativePath":"深度学习/李宏毅/2023年&2024年/6.评估模型能力&模型的安全性.md","filePath":"深度学习/李宏毅/2023年&2024年/6.评估模型能力&模型的安全性.md"}'),r={name:"深度学习/李宏毅/2023年&2024年/6.评估模型能力&模型的安全性.md"};function o(s,a,h,c,n,d){return i(),l("div",null,a[0]||(a[0]=[t('<h1 id="评估模型的能力" tabindex="-1">评估模型的能力 <a class="header-anchor" href="#评估模型的能力" aria-label="Permalink to &quot;评估模型的能力&quot;">​</a></h1><ol><li>使用人工构件的比较复杂难以回答的问题集</li><li>只做选择题（也不能确定大模型是在选择 A、B、C、D还是根据答案选择A、B、C、D)</li></ol><h2 id="评判标准" tabindex="-1">评判标准 <a class="header-anchor" href="#评判标准" aria-label="Permalink to &quot;评判标准&quot;">​</a></h2><ol><li>其它大模型进行评分</li><li>人工评分</li></ol><h2 id="评判存在问题" tabindex="-1">评判存在问题 <a class="header-anchor" href="#评判存在问题" aria-label="Permalink to &quot;评判存在问题&quot;">​</a></h2><ol><li>人工评判可能具备主观性，不一定正确</li><li>其它大模型的评判也不一定正确，可能具备偏向性（比如偏向于大文本的回答）</li></ol><h2 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h2><p>目前的评判还是有待讨论的，并不是完善的</p><h1 id="模型的安全性" tabindex="-1">模型的安全性 <a class="header-anchor" href="#模型的安全性" aria-label="Permalink to &quot;模型的安全性&quot;">​</a></h1><ol><li><p>大模型说错话：进行资料的校验（只能保证大模型输出能找到出处，不能保证出处说的就一定是对的）</p></li><li><p>大模型自带偏见：可能因为训练资料的问题导致回答有一定的倾向性，比如软件工程师，女性是比较适合的！在各个阶段（预训练、微调、输出之前、输出之后）进行偏见的修正 <img src="https://github.com/user-attachments/assets/0411e401-7f78-4771-9143-902bcd058c64" alt="Image"></p></li><li><p>检验一些答案是否是大模型输出的：可能会随着版本的升级而导致原来训练的校验器失效，而且能否真的能准确校验也是一个问题 <img src="https://github.com/user-attachments/assets/f3d24f34-1fd4-4eda-9f5f-64dfcc7f35be" alt="Image"></p></li><li><p>突破大模型的限制，输出一些错误的数据 <img src="https://github.com/user-attachments/assets/4a744294-4ed3-441a-a106-e67ac4456699" alt="Image"></p></li></ol><h2 id="jailbreak" tabindex="-1">Jailbreak <a class="header-anchor" href="#jailbreak" aria-label="Permalink to &quot;Jailbreak&quot;">​</a></h2><ol><li>使用特殊的文字触发</li><li>使用一些比较少见的语言（可能它只是训练了英语的防御模式）</li><li>给予冲突的指令</li><li>试图说服语言模型：先跟大模型说一个虚构的故事，让它忽略我们接下来想要提问的问题</li></ol>',12)]))}const u=e(r,[["render",o]]);export{p as __pageData,u as default};
