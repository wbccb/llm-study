# Local_Pdf_Chat_RAG

参照 https://github.com/weiwill88/Local_Pdf_Chat_RAG 进行动手实践RAG整套流程的搭建，旨在学习RAG的基础知识，从而更好地理解主流开源RAG库代码的精髓以及进行二次开发

![image.svg](docs/image1.svg)




## Chroma DB

Chroma DB 是一个开源的向量数据库（Vector Database），专门设计用于存储、检索和管理向量嵌入（Embeddings）。它是为机器学习和人工智能应用（如自然语言处理、图像处理等）量身定制的，能够高效地处理高维向量数据

**适用场景**
- 语义搜索：基于文本嵌入的语义相似性搜索。
- 推荐系统：通过向量相似性为用户推荐内容。
- 图像检索：基于图像嵌入的相似图像搜索。
- 问答系统：基于嵌入的问答和知识检索。
- 聚类和分类：对高维向量数据进行聚类或分类

![img.png](img.png)



## all-MiniLM-L6-v2


all-MiniLM-L6-v2 是一个基于 Transformer 架构的轻量级语言模型，专门用于生成高质量的文本嵌入（Text Embeddings）。它是由 Microsoft 团队开发的，属于 MiniLM 系列模型之一，旨在提供高效且性能优异的文本表示能力，适用于各种自然语言处理（NLP）任务（如语义搜索、文本分类、聚类、问答系统等）

![img_1.png](img_1.png)



## BM25

BM25（Best Match 25）是一种经典的信息检索算法，用于衡量文档与查询之间的相关性。它是 TF-IDF（Term Frequency-Inverse Document Frequency）的改进版本，旨在更准确地评估文档在给定查询下的匹配程度。BM25 是搜索引擎和全文检索系统中广泛使用的算法之一


BM25 的核心思想是通过以下两个因素来评估文档的相关性：
- 词频（Term Frequency, TF）：查询中的词在文档中出现的频率。
- 逆文档频率（Inverse Document Frequency, IDF）：查询中的词在整个文档集合中的稀有程度。
BM25 在 TF-IDF 的基础上引入了文档长度归一化，以解决长文档可能包含更多无关词汇的问题。

适用场景
- 搜索引擎：用于网页、文档等全文检索。
- 问答系统：基于关键词匹配的问答检索。
- 推荐系统：通过关键词匹配推荐相关内容。

示例代码：
```python
from rank_bm25 import BM25Okapi

# 文档集合
documents = [
    "The cat sat on the mat.",
    "The dog played in the yard.",
    "Cats and dogs are pets."
]

# 分词
tokenized_docs = [doc.split() for doc in documents]

# 初始化 BM25
bm25 = BM25Okapi(tokenized_docs)

# 查询
query = "cat dog"
tokenized_query = query.split()

# 计算得分
scores = bm25.get_scores(tokenized_query)
print(scores)

# 返回最相关的文档
best_doc_index = scores.argmax()
print("Best document:", documents[best_doc_index])
```

## jieba

jieba 是一个流行的 Python 中文分词库，专门用于将中文文本切分成词语（即分词）。它是中文自然语言处理（NLP）任务中常用的工具之一，具有高效、易用和功能丰富的特点

**适用场景**
- 中文文本预处理：用于机器学习或深度学习的文本数据预处理。
- 搜索引擎：构建中文搜索引擎的分词模块。
- 文本分析：如情感分析、主题建模等。
- 信息提取：如关键词提取、实体识别等。


## LangChain
LangChain 是一个用于构建基于 语言模型（LLM，Large Language Models） 的应用程序的框架。它旨在简化与语言模型的交互，并支持构建复杂的、功能丰富的应用，如问答系统、聊天机器人、文档分析工具等。LangChain 提供了模块化的组件和工具，使开发者能够轻松地将语言模型与其他数据源、工具和逻辑集成在一起


### langchain.text_splitter
langchain.text_splitter 是 LangChain 库中的一个模块，专门用于将文本分割成更小的块（chunks）

langchain.text_splitter 提供了多种文本分割器，可以根据不同的需求将文本分割成块。常见的分割方式包括：
- 按字符分割：将文本按固定字符数分割。
- 按句子分割：将文本按句子边界分割。
- 按段落分割：将文本按段落分割。
- 按标记（Token）分割：将文本按模型的标记（Token）数分割（适合用于语言模型输入）。
- 递归分割：结合多种分割方式，递归地将文本分割成更小的块

## SerpAPI搜索

SerpAPI 搜索是一种基于 API 的搜索引擎结果获取服务，专为开发者设计，能够通过编程接口从主流搜索引擎（如 Google、Bing 等）中高效获取结构化数据

1. 支持 Google、Bing、Yahoo 等多个搜索引擎，开发者可通过参数 engine 快速切换，例如指定 "engine": "bing" 调用必应搜索
2. 提供一致的 JSON 格式返回结果，简化数据解析流程
3. 支持地理位置（gl）、语言（hl）等参数调整，例如 "gl": "us" 指定美国地区、"hl": "en" 设置英语界面 + 可自定义搜索类型（如网页、图片、新闻），满足不同业务需求
4. 通过 Python 的 SerpAPIWrapper 工具库快速调用 API，仅需 3-5 行代码即可完成搜索功能

## MRKL Agent
- MRKL: 模块化推理、知识和语言系统
- Agent是大模型(LLM)

MRKL Agent就是会使用工具的大模型


## 知识图谱

在知识图谱中，实体是构成语义网络的核心节点，通过“实体-关系-实体”三元组构建结构化知识（如<曹操，儿子，曹丕>）。两者的区别在于：
- 实体是单一对象或概念的抽象；
- 知识图谱是实体及其关系的集合，强调关联性与推理能力

> 知识图谱的概念最早由谷歌于2012年提出，旨在提升搜索引擎对用户意图的理解能力，例如搜索“玛丽·居里”时直接展示其生平、成就及关联人物，而非仅提供网页链接


### 知识构建

1. 数据采集与清洗：从结构化数据库（如CRM系统）、非结构化文档（如产品手册、工单记录）及网络资源中提取原始数据。例如，电商客服系统需整合商品属性（价格、库存）、用户评价、退换货政策等
2. 实体关系抽取：例如在金融场景中，通过依存句法分析提取“企业-法人-股权比例”三元组
3. 知识存储与更新：采用图数据库（Neo4j、Nebula Graph）存储三元组，并建立索引加速查询

### 问题解析

**1. 意图识别与实体链接** 

通过语义分析确定用户问题类型（如咨询、投诉）并链接到图谱实体。例如用户问“如何重置路由器密码”，系统识别意图为“设备操作指南”，并定位实体“路由器”

**2. 多跳推理路径生成**

对复杂问题分解子查询。例如用户问“周杰伦的专辑中有哪些歌曲获得过金曲奖？”，流程如下：
- 子查询1：检索「周杰伦-创作-专辑」关系 → 得到专辑列表
- 子查询2：遍历各专辑的「歌曲-获奖-金曲奖」路径 → 筛选结果。

### 语义推理

**1. 基于规则的推理**

应用预定义逻辑处理特定场景
> 例如，用户问“订单未到货能否退款？”，系统根据图谱中「订单状态-物流状态-退款政策」链条判断：若物流显示“运输中”则建议等待；若显示“丢失”则触发退款流程


**2. 图嵌入推理**

利用TransE等算法预测隐含关系
> 例如客服系统发现用户多次询问“手机发热”，自动关联图谱中的“电池型号-散热设计缺陷”历史工单，提示可能存在的产品批次问题

### 答案生成

**1. 结构化答案抽取**

直接返回图谱中的属性值
> 例如用户问“华为P60的屏幕尺寸”，系统查询「华为P60-屏幕尺寸-6.7英寸」并生成答案

**2. 自然语言生成**

结合模板与LLM生成多模态回复
> 例如用户问“如何解决打印机卡纸”，系统调用图谱中的「故障原因-解决步骤」数据，通过GPT-4生成带步骤图示的回复

**3. 多轮对话管理**

记录上下文并动态扩展查询
> 例如用户追问“刚才说的路由器密码重置对AX3000型号有效吗？”，系统基于对话历史锁定具体产品型号，校验知识图谱中的兼容性信息


## 语义 & 意图


### 意图数据构建

1. 人工构建基础框架：
- 业务规则定义：人工根据企业服务场景定义意图分类，例如电商场景中的“退货申请”“物流查询”“商品咨询”等
- 知识库标注：对历史对话数据进行人工标注，例如将“如何退款？”标注为“退款流程”意图，为后续模型训练提供基准数据

2. 机器学习模型自动化扩展
- 监督学习：利用标注数据训练分类模型（如BERT、SVM），通过语义相似度匹配新问题与已知意图。例如，用户输入“快递到哪了？”会被自动归类到“物流查询”意图
- 无监督学习：通过聚类算法（如K-means）发现未标注数据中的潜在意图类别，辅助人工扩展意图库

3. 大语言模型（LLM）增强
- 意图生成：利用GPT-4等模型自动分析用户问题，生成可能的意图标签（如将“手机充不进电”映射到“设备故障报修”意图）
- 意图泛化：通过提示工程（Prompt Engineering）让模型理解意图的变体表达，例如“我想取消订单”和“订单不要了”均对应“订单取消”意图

### 意图含义
- 意图（Intent）：指用户通过自然语言表达的需求或目的
- 意图识别：将用户的自然语言输入（如“查话费”或“如何更改套餐”）分类为预定义的任务类别
> 例如，在电信场景中，用户提问“我的流量用完了”会被识别为“流量查询”或“套餐升级”意图



### 意图技术实现
- 基于规则的系统：依赖关键词匹配（如“查话费”直接触发余额查询），适合简单场景但灵活性差。
- 机器学习模型：如支持向量机（SVM）、随机森林，通过标注数据训练模型，支持多意图识别。
- 深度学习模型：如BERT、GPT，利用上下文理解处理复杂语义，例如同时识别“查话费并改套餐”中的多意图


### 语义训练过程

1. 构建实体、关系、意图的数据
2. 自然语言处理（NLP）模型训练
- 意图识别与实体抽取：利用BERT、LSTM等模型，通过标注数据训练模型自动识别用户问题中的意图和关键实体（如时间、地点）
- 语义相似度计算：通过词向量模型（如Word2Vec）或句向量模型（如Sentence-BERT），匹配用户问题与知识库答案的语义相关性
3. 动态知识融合与更新
- 知识图谱自动化扩展：从非结构化文本（如工单记录、产品手册）中抽取新实体关系，例如通过依存句法分析发现“iPhone 15支持Type-C充电”等新知识
- 在线学习优化：根据用户反馈实时调整模型，例如将误判的“换货”问题重新归类至正确意图
4. 多模态语义整合
- 语音与图像处理：结合ASR（语音转文本）和OCR（图片识别）技术，将语音提问、故障截图转化为文本信息，再通过NLP解析语义
- 情感分析增强：基于用户语气或表情符号（如愤怒表情）调整应答策略，提升服务个性化

> 本质就是不断训练：可以通过用户输入=>解析的语义去匹配正确的 实体 + 意图 （实体-关系-属性）

### 语义含义

语义是指用户输入的自然语言背后隐含的意图、上下文关系及深层含义，而非单纯的文字表面信息。

其核心是通过对语言结构的分析，将用户问题转化为机器可理解的逻辑表达，并实现精准的应答匹配

- 意图识别：理解用户问题的根本需求
- 上下文：捕捉对话中的历史信息
- 情感和歧义处：识别用户情绪以及消除多义词的干扰


### 语义技术实现

- 自然语言处理（NLP）：利用BERT等预训练模型进行分词、句法分析，生成文本向量表示；
- 知识图谱：构建实体关系网络（如“产品-故障-解决方案”），支持语义推理；
- 深度学习算法：通过LSTM、Transformer模型捕捉长距离语义依赖


