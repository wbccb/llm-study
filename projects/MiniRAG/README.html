<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Local_Pdf_Chat_RAG | 大模型相关学习电子书</title>
    <meta name="description" content="A VitePress site">
    <meta name="generator" content="VitePress v1.5.0">
    <link rel="preload stylesheet" href="/llm-study/assets/style.D1XloW-X.css" as="style">
    <link rel="preload stylesheet" href="/llm-study/vp-icons.css" as="style">
    
    <script type="module" src="/llm-study/assets/app.C8K0wDnH.js"></script>
    <link rel="preload" href="/llm-study/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/llm-study/assets/chunks/theme.BY3UI_tb.js">
    <link rel="modulepreload" href="/llm-study/assets/chunks/framework.OqxnQCTf.js">
    <link rel="modulepreload" href="/llm-study/assets/projects_MiniRAG_README.md.D-OmG4od.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-ba1e04ff><!--[--><!--]--><!--[--><span tabindex="-1" data-v-97ea0100></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-97ea0100> Skip to content </a><!--]--><!----><header class="VPNav" data-v-ba1e04ff data-v-b5170f91><div class="VPNavBar" data-v-b5170f91 data-v-c5a70330><div class="wrapper" data-v-c5a70330><div class="container" data-v-c5a70330><div class="title" data-v-c5a70330><div class="VPNavBarTitle has-sidebar" data-v-c5a70330 data-v-c6706323><a class="title" href="/llm-study/" data-v-c6706323><!--[--><!--]--><!----><span data-v-c6706323>大模型相关学习电子书</span><!--[--><!--]--></a></div></div><div class="content" data-v-c5a70330><div class="content-body" data-v-c5a70330><!--[--><!--]--><div class="VPNavBarSearch search" data-v-c5a70330><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-c5a70330 data-v-a30a5015><span id="main-nav-aria-label" class="visually-hidden" data-v-a30a5015> Main Navigation </span><!--[--><!--[--><a class="VPLink link vp-external-link-icon VPNavBarMenuLink" href="https://github.com/wbccb/llm-study" target="_blank" rel="noreferrer" tabindex="0" data-v-a30a5015 data-v-11bf523d><!--[--><span data-v-11bf523d>Home</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-c5a70330 data-v-6f47f4f1><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6f47f4f1 data-v-94ce7627 data-v-ef45cb02><span class="check" data-v-ef45cb02><span class="icon" data-v-ef45cb02><!--[--><span class="vpi-sun sun" data-v-94ce7627></span><span class="vpi-moon moon" data-v-94ce7627></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-c5a70330 data-v-e81dec13 data-v-14929940><!--[--><a class="VPSocialLink no-icon" href="https://github.com/wbccb" aria-label="github" target="_blank" rel="noopener" data-v-14929940 data-v-75a89838><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-c5a70330 data-v-2cdb8833 data-v-a8d23b86><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-a8d23b86><span class="vpi-more-horizontal icon" data-v-a8d23b86></span></button><div class="menu" data-v-a8d23b86><div class="VPMenu" data-v-a8d23b86 data-v-7cf740b3><!----><!--[--><!--[--><!----><div class="group" data-v-2cdb8833><div class="item appearance" data-v-2cdb8833><p class="label" data-v-2cdb8833>Appearance</p><div class="appearance-action" data-v-2cdb8833><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-2cdb8833 data-v-94ce7627 data-v-ef45cb02><span class="check" data-v-ef45cb02><span class="icon" data-v-ef45cb02><!--[--><span class="vpi-sun sun" data-v-94ce7627></span><span class="vpi-moon moon" data-v-94ce7627></span><!--]--></span></span></button></div></div></div><div class="group" data-v-2cdb8833><div class="item social-links" data-v-2cdb8833><div class="VPSocialLinks social-links-list" data-v-2cdb8833 data-v-14929940><!--[--><a class="VPSocialLink no-icon" href="https://github.com/wbccb" aria-label="github" target="_blank" rel="noopener" data-v-14929940 data-v-75a89838><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-c5a70330 data-v-2f88690c><span class="container" data-v-2f88690c><span class="top" data-v-2f88690c></span><span class="middle" data-v-2f88690c></span><span class="bottom" data-v-2f88690c></span></span></button></div></div></div></div><div class="divider" data-v-c5a70330><div class="divider-line" data-v-c5a70330></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-ba1e04ff data-v-b8c7cf07><div class="container" data-v-b8c7cf07><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-b8c7cf07><span class="vpi-align-left menu-icon" data-v-b8c7cf07></span><span class="menu-text" data-v-b8c7cf07>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-b8c7cf07 data-v-239c32ad><button data-v-239c32ad>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-ba1e04ff data-v-119ab7f8><div class="curtain" data-v-119ab7f8></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-119ab7f8><span class="visually-hidden" id="sidebar-aria-label" data-v-119ab7f8> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-f81fd976><section class="VPSidebarItem level-0" data-v-f81fd976 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h2 class="text" data-v-b849b590>python</h2><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/python/1.%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>基础知识</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-f81fd976><section class="VPSidebarItem level-0" data-v-f81fd976 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h2 class="text" data-v-b849b590>深度学习</h2><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>基本概念</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/DeepSeek.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>DeepSeek</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-f81fd976><section class="VPSidebarItem level-0" data-v-f81fd976 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h2 class="text" data-v-b849b590>深度学习-李宏毅</h2><!----></div><div class="items" data-v-b849b590><!--[--><section class="VPSidebarItem level-1" data-v-b849b590 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h3 class="text" data-v-b849b590>2021年 & 2022年</h3><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2021%E5%B9%B4&amp;2022%E5%B9%B4/1.%E4%BA%86%E8%A7%A3%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>了解线性模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2021%E5%B9%B4&amp;2022%E5%B9%B4/2.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>机器学习框架</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1" data-v-b849b590 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h3 class="text" data-v-b849b590>2023年&2024年</h3><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/1.chatGPT.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>chatGPT</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/2.%E7%94%9F%E6%88%90%E5%BC%8FAI.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>生成式AI</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/3.%E4%B8%8D%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B=%3E%E5%BC%BA%E5%8C%96%E6%A8%A1%E5%9E%8B.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>不训练模型=>强化模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/4.%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%AD%A5%E9%AA%A4.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>训练模型步骤</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/5.Transformer.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>Transformer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/6.%E8%AF%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B&amp;%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>评估模型能力&模型的安全性</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/7.%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>生成策略</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85/2023%E5%B9%B4&amp;2024%E5%B9%B4/8.Video%E7%9B%B8%E5%85%B3%E7%9A%84%E7%94%9F%E6%88%90%E5%BC%8FAI%E6%8A%80%E6%9C%AF.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>Video相关的生成式AI技术</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><div class="no-transition group" data-v-f81fd976><section class="VPSidebarItem level-0" data-v-f81fd976 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h2 class="text" data-v-b849b590>知识库</h2><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-1 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E7%9F%A5%E8%AF%86%E5%BA%93/NLP+%E5%A4%A7%E6%A8%A1%E5%9E%8B=%3E%E9%97%AE%E7%AD%94.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>NLP+大模型=>问答</p><!--]--></a><!----></div><!----></div><section class="VPSidebarItem level-1" data-v-b849b590 data-v-b849b590><div class="item" role="button" tabindex="0" data-v-b849b590><div class="indicator" data-v-b849b590></div><h3 class="text" data-v-b849b590>RAGFlow源码分析</h3><!----></div><div class="items" data-v-b849b590><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b849b590 data-v-b849b590><div class="item" data-v-b849b590><div class="indicator" data-v-b849b590></div><a class="VPLink link link" href="/llm-study/docs/%E7%9F%A5%E8%AF%86%E5%BA%93/RAG/RAGFlow%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/%E6%96%87%E6%A1%A3%E9%A2%84%E5%A4%84%E7%90%86%E9%98%B6%E6%AE%B5/%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0&amp;%E8%A7%A3%E6%9E%90%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B.html" data-v-b849b590><!--[--><p class="text" data-v-b849b590>文件上传&解析整体流程</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-ba1e04ff data-v-58605e9b><div class="VPDoc has-sidebar has-aside" data-v-58605e9b data-v-f9254922><!--[--><!--]--><div class="container" data-v-f9254922><div class="aside" data-v-f9254922><div class="aside-curtain" data-v-f9254922></div><div class="aside-container" data-v-f9254922><div class="aside-content" data-v-f9254922><div class="VPDocAside" data-v-f9254922 data-v-da6ed907><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-da6ed907 data-v-d887b119><div class="content" data-v-d887b119><div class="outline-marker" data-v-d887b119></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-d887b119>On this page</div><ul class="VPDocOutlineItem root" data-v-d887b119 data-v-43146e3a><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-da6ed907></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-f9254922><div class="content-container" data-v-f9254922><!--[--><!--]--><main class="main" data-v-f9254922><div style="position:relative;" class="vp-doc _llm-study_projects_MiniRAG_README" data-v-f9254922><div><h1 id="local-pdf-chat-rag" tabindex="-1">Local_Pdf_Chat_RAG <a class="header-anchor" href="#local-pdf-chat-rag" aria-label="Permalink to &quot;Local_Pdf_Chat_RAG&quot;">​</a></h1><p>参照 <a href="https://github.com/weiwill88/Local_Pdf_Chat_RAG" target="_blank" rel="noreferrer">https://github.com/weiwill88/Local_Pdf_Chat_RAG</a> 进行动手实践RAG整套流程的搭建，旨在学习RAG的基础知识，从而更好地理解主流开源RAG库代码的精髓以及进行二次开发</p><p><img src="/llm-study/assets/image1.C5Lc-Dz9.svg" alt="image.svg"></p><h2 id="chroma-db" tabindex="-1">Chroma DB <a class="header-anchor" href="#chroma-db" aria-label="Permalink to &quot;Chroma DB&quot;">​</a></h2><p>Chroma DB 是一个开源的向量数据库（Vector Database），专门设计用于存储、检索和管理向量嵌入（Embeddings）。它是为机器学习和人工智能应用（如自然语言处理、图像处理等）量身定制的，能够高效地处理高维向量数据</p><p><strong>适用场景</strong></p><ul><li>语义搜索：基于文本嵌入的语义相似性搜索。</li><li>推荐系统：通过向量相似性为用户推荐内容。</li><li>图像检索：基于图像嵌入的相似图像搜索。</li><li>问答系统：基于嵌入的问答和知识检索。</li><li>聚类和分类：对高维向量数据进行聚类或分类</li></ul><p><img src="/llm-study/assets/img.TcBEYvlE.png" alt="img.png"></p><h2 id="all-minilm-l6-v2" tabindex="-1">all-MiniLM-L6-v2 <a class="header-anchor" href="#all-minilm-l6-v2" aria-label="Permalink to &quot;all-MiniLM-L6-v2&quot;">​</a></h2><p>all-MiniLM-L6-v2 是一个基于 Transformer 架构的轻量级语言模型，专门用于生成高质量的文本嵌入（Text Embeddings）。它是由 Microsoft 团队开发的，属于 MiniLM 系列模型之一，旨在提供高效且性能优异的文本表示能力，适用于各种自然语言处理（NLP）任务（如语义搜索、文本分类、聚类、问答系统等）</p><p><img src="/llm-study/assets/img_1.C-Xx8IcV.png" alt="img_1.png"></p><h2 id="bm25" tabindex="-1">BM25 <a class="header-anchor" href="#bm25" aria-label="Permalink to &quot;BM25&quot;">​</a></h2><p>BM25（Best Match 25）是一种经典的信息检索算法，用于衡量文档与查询之间的相关性。它是 TF-IDF（Term Frequency-Inverse Document Frequency）的改进版本，旨在更准确地评估文档在给定查询下的匹配程度。BM25 是搜索引擎和全文检索系统中广泛使用的算法之一</p><p>BM25 的核心思想是通过以下两个因素来评估文档的相关性：</p><ul><li>词频（Term Frequency, TF）：查询中的词在文档中出现的频率。</li><li>逆文档频率（Inverse Document Frequency, IDF）：查询中的词在整个文档集合中的稀有程度。 BM25 在 TF-IDF 的基础上引入了文档长度归一化，以解决长文档可能包含更多无关词汇的问题。</li></ul><p>适用场景</p><ul><li>搜索引擎：用于网页、文档等全文检索。</li><li>问答系统：基于关键词匹配的问答检索。</li><li>推荐系统：通过关键词匹配推荐相关内容。</li></ul><p>示例代码：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> rank_bm25 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> BM25Okapi</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 文档集合</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">documents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;The cat sat on the mat.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;The dog played in the yard.&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;Cats and dogs are pets.&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 分词</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenized_docs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [doc.split() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> doc </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> documents]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化 BM25</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">bm25 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> BM25Okapi(tokenized_docs)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查询</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;cat dog&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">tokenized_query </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> query.split()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 计算得分</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">scores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> bm25.get_scores(tokenized_query)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(scores)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回最相关的文档</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">best_doc_index </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scores.argmax()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Best document:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, documents[best_doc_index])</span></span></code></pre></div><h2 id="jieba" tabindex="-1">jieba <a class="header-anchor" href="#jieba" aria-label="Permalink to &quot;jieba&quot;">​</a></h2><p>jieba 是一个流行的 Python 中文分词库，专门用于将中文文本切分成词语（即分词）。它是中文自然语言处理（NLP）任务中常用的工具之一，具有高效、易用和功能丰富的特点</p><p><strong>适用场景</strong></p><ul><li>中文文本预处理：用于机器学习或深度学习的文本数据预处理。</li><li>搜索引擎：构建中文搜索引擎的分词模块。</li><li>文本分析：如情感分析、主题建模等。</li><li>信息提取：如关键词提取、实体识别等。</li></ul><h2 id="langchain" tabindex="-1">LangChain <a class="header-anchor" href="#langchain" aria-label="Permalink to &quot;LangChain&quot;">​</a></h2><p>LangChain 是一个用于构建基于 语言模型（LLM，Large Language Models） 的应用程序的框架。它旨在简化与语言模型的交互，并支持构建复杂的、功能丰富的应用，如问答系统、聊天机器人、文档分析工具等。LangChain 提供了模块化的组件和工具，使开发者能够轻松地将语言模型与其他数据源、工具和逻辑集成在一起</p><h3 id="langchain-text-splitter" tabindex="-1">langchain.text_splitter <a class="header-anchor" href="#langchain-text-splitter" aria-label="Permalink to &quot;langchain.text_splitter&quot;">​</a></h3><p>langchain.text_splitter 是 LangChain 库中的一个模块，专门用于将文本分割成更小的块（chunks）</p><p>langchain.text_splitter 提供了多种文本分割器，可以根据不同的需求将文本分割成块。常见的分割方式包括：</p><ul><li>按字符分割：将文本按固定字符数分割。</li><li>按句子分割：将文本按句子边界分割。</li><li>按段落分割：将文本按段落分割。</li><li>按标记（Token）分割：将文本按模型的标记（Token）数分割（适合用于语言模型输入）。</li><li>递归分割：结合多种分割方式，递归地将文本分割成更小的块</li></ul><h2 id="serpapi搜索" tabindex="-1">SerpAPI搜索 <a class="header-anchor" href="#serpapi搜索" aria-label="Permalink to &quot;SerpAPI搜索&quot;">​</a></h2><p>SerpAPI 搜索是一种基于 API 的搜索引擎结果获取服务，专为开发者设计，能够通过编程接口从主流搜索引擎（如 Google、Bing 等）中高效获取结构化数据</p><ol><li>支持 Google、Bing、Yahoo 等多个搜索引擎，开发者可通过参数 engine 快速切换，例如指定 &quot;engine&quot;: &quot;bing&quot; 调用必应搜索</li><li>提供一致的 JSON 格式返回结果，简化数据解析流程</li><li>支持地理位置（gl）、语言（hl）等参数调整，例如 &quot;gl&quot;: &quot;us&quot; 指定美国地区、&quot;hl&quot;: &quot;en&quot; 设置英语界面 + 可自定义搜索类型（如网页、图片、新闻），满足不同业务需求</li><li>通过 Python 的 SerpAPIWrapper 工具库快速调用 API，仅需 3-5 行代码即可完成搜索功能</li></ol><h2 id="mrkl-agent" tabindex="-1">MRKL Agent <a class="header-anchor" href="#mrkl-agent" aria-label="Permalink to &quot;MRKL Agent&quot;">​</a></h2><ul><li>MRKL: 模块化推理、知识和语言系统</li><li>Agent是大模型(LLM)</li></ul><p>MRKL Agent就是会使用工具的大模型</p><h2 id="知识图谱" tabindex="-1">知识图谱 <a class="header-anchor" href="#知识图谱" aria-label="Permalink to &quot;知识图谱&quot;">​</a></h2><p>在知识图谱中，实体是构成语义网络的核心节点，通过“实体-关系-实体”三元组构建结构化知识（如&lt;曹操，儿子，曹丕&gt;）。两者的区别在于：</p><ul><li>实体是单一对象或概念的抽象；</li><li>知识图谱是实体及其关系的集合，强调关联性与推理能力</li></ul><blockquote><p>知识图谱的概念最早由谷歌于2012年提出，旨在提升搜索引擎对用户意图的理解能力，例如搜索“玛丽·居里”时直接展示其生平、成就及关联人物，而非仅提供网页链接</p></blockquote><h3 id="知识构建" tabindex="-1">知识构建 <a class="header-anchor" href="#知识构建" aria-label="Permalink to &quot;知识构建&quot;">​</a></h3><ol><li>数据采集与清洗：从结构化数据库（如CRM系统）、非结构化文档（如产品手册、工单记录）及网络资源中提取原始数据。例如，电商客服系统需整合商品属性（价格、库存）、用户评价、退换货政策等</li><li>实体关系抽取：例如在金融场景中，通过依存句法分析提取“企业-法人-股权比例”三元组</li><li>知识存储与更新：采用图数据库（Neo4j、Nebula Graph）存储三元组，并建立索引加速查询</li></ol><h3 id="问题解析" tabindex="-1">问题解析 <a class="header-anchor" href="#问题解析" aria-label="Permalink to &quot;问题解析&quot;">​</a></h3><p><strong>1. 意图识别与实体链接</strong></p><p>通过语义分析确定用户问题类型（如咨询、投诉）并链接到图谱实体。例如用户问“如何重置路由器密码”，系统识别意图为“设备操作指南”，并定位实体“路由器”</p><p><strong>2. 多跳推理路径生成</strong></p><p>对复杂问题分解子查询。例如用户问“周杰伦的专辑中有哪些歌曲获得过金曲奖？”，流程如下：</p><ul><li>子查询1：检索「周杰伦-创作-专辑」关系 → 得到专辑列表</li><li>子查询2：遍历各专辑的「歌曲-获奖-金曲奖」路径 → 筛选结果。</li></ul><h3 id="语义推理" tabindex="-1">语义推理 <a class="header-anchor" href="#语义推理" aria-label="Permalink to &quot;语义推理&quot;">​</a></h3><p><strong>1. 基于规则的推理</strong></p><p>应用预定义逻辑处理特定场景</p><blockquote><p>例如，用户问“订单未到货能否退款？”，系统根据图谱中「订单状态-物流状态-退款政策」链条判断：若物流显示“运输中”则建议等待；若显示“丢失”则触发退款流程</p></blockquote><p><strong>2. 图嵌入推理</strong></p><p>利用TransE等算法预测隐含关系</p><blockquote><p>例如客服系统发现用户多次询问“手机发热”，自动关联图谱中的“电池型号-散热设计缺陷”历史工单，提示可能存在的产品批次问题</p></blockquote><h3 id="答案生成" tabindex="-1">答案生成 <a class="header-anchor" href="#答案生成" aria-label="Permalink to &quot;答案生成&quot;">​</a></h3><p><strong>1. 结构化答案抽取</strong></p><p>直接返回图谱中的属性值</p><blockquote><p>例如用户问“华为P60的屏幕尺寸”，系统查询「华为P60-屏幕尺寸-6.7英寸」并生成答案</p></blockquote><p><strong>2. 自然语言生成</strong></p><p>结合模板与LLM生成多模态回复</p><blockquote><p>例如用户问“如何解决打印机卡纸”，系统调用图谱中的「故障原因-解决步骤」数据，通过GPT-4生成带步骤图示的回复</p></blockquote><p><strong>3. 多轮对话管理</strong></p><p>记录上下文并动态扩展查询</p><blockquote><p>例如用户追问“刚才说的路由器密码重置对AX3000型号有效吗？”，系统基于对话历史锁定具体产品型号，校验知识图谱中的兼容性信息</p></blockquote><h2 id="语义-意图" tabindex="-1">语义 &amp; 意图 <a class="header-anchor" href="#语义-意图" aria-label="Permalink to &quot;语义 &amp; 意图&quot;">​</a></h2><h3 id="意图数据构建" tabindex="-1">意图数据构建 <a class="header-anchor" href="#意图数据构建" aria-label="Permalink to &quot;意图数据构建&quot;">​</a></h3><ol><li>人工构建基础框架：</li></ol><ul><li>业务规则定义：人工根据企业服务场景定义意图分类，例如电商场景中的“退货申请”“物流查询”“商品咨询”等</li><li>知识库标注：对历史对话数据进行人工标注，例如将“如何退款？”标注为“退款流程”意图，为后续模型训练提供基准数据</li></ul><ol start="2"><li>机器学习模型自动化扩展</li></ol><ul><li>监督学习：利用标注数据训练分类模型（如BERT、SVM），通过语义相似度匹配新问题与已知意图。例如，用户输入“快递到哪了？”会被自动归类到“物流查询”意图</li><li>无监督学习：通过聚类算法（如K-means）发现未标注数据中的潜在意图类别，辅助人工扩展意图库</li></ul><ol start="3"><li>大语言模型（LLM）增强</li></ol><ul><li>意图生成：利用GPT-4等模型自动分析用户问题，生成可能的意图标签（如将“手机充不进电”映射到“设备故障报修”意图）</li><li>意图泛化：通过提示工程（Prompt Engineering）让模型理解意图的变体表达，例如“我想取消订单”和“订单不要了”均对应“订单取消”意图</li></ul><h3 id="意图含义" tabindex="-1">意图含义 <a class="header-anchor" href="#意图含义" aria-label="Permalink to &quot;意图含义&quot;">​</a></h3><ul><li>意图（Intent）：指用户通过自然语言表达的需求或目的</li><li>意图识别：将用户的自然语言输入（如“查话费”或“如何更改套餐”）分类为预定义的任务类别</li></ul><blockquote><p>例如，在电信场景中，用户提问“我的流量用完了”会被识别为“流量查询”或“套餐升级”意图</p></blockquote><h3 id="意图技术实现" tabindex="-1">意图技术实现 <a class="header-anchor" href="#意图技术实现" aria-label="Permalink to &quot;意图技术实现&quot;">​</a></h3><ul><li>基于规则的系统：依赖关键词匹配（如“查话费”直接触发余额查询），适合简单场景但灵活性差。</li><li>机器学习模型：如支持向量机（SVM）、随机森林，通过标注数据训练模型，支持多意图识别。</li><li>深度学习模型：如BERT、GPT，利用上下文理解处理复杂语义，例如同时识别“查话费并改套餐”中的多意图</li></ul><h3 id="语义训练过程" tabindex="-1">语义训练过程 <a class="header-anchor" href="#语义训练过程" aria-label="Permalink to &quot;语义训练过程&quot;">​</a></h3><ol><li>构建实体、关系、意图的数据</li><li>自然语言处理（NLP）模型训练</li></ol><ul><li>意图识别与实体抽取：利用BERT、LSTM等模型，通过标注数据训练模型自动识别用户问题中的意图和关键实体（如时间、地点）</li><li>语义相似度计算：通过词向量模型（如Word2Vec）或句向量模型（如Sentence-BERT），匹配用户问题与知识库答案的语义相关性</li></ul><ol start="3"><li>动态知识融合与更新</li></ol><ul><li>知识图谱自动化扩展：从非结构化文本（如工单记录、产品手册）中抽取新实体关系，例如通过依存句法分析发现“iPhone 15支持Type-C充电”等新知识</li><li>在线学习优化：根据用户反馈实时调整模型，例如将误判的“换货”问题重新归类至正确意图</li></ul><ol start="4"><li>多模态语义整合</li></ol><ul><li>语音与图像处理：结合ASR（语音转文本）和OCR（图片识别）技术，将语音提问、故障截图转化为文本信息，再通过NLP解析语义</li><li>情感分析增强：基于用户语气或表情符号（如愤怒表情）调整应答策略，提升服务个性化</li></ul><blockquote><p>本质就是不断训练：可以通过用户输入=&gt;解析的语义去匹配正确的 实体 + 意图 （实体-关系-属性）</p></blockquote><h3 id="语义含义" tabindex="-1">语义含义 <a class="header-anchor" href="#语义含义" aria-label="Permalink to &quot;语义含义&quot;">​</a></h3><p>语义是指用户输入的自然语言背后隐含的意图、上下文关系及深层含义，而非单纯的文字表面信息。</p><p>其核心是通过对语言结构的分析，将用户问题转化为机器可理解的逻辑表达，并实现精准的应答匹配</p><ul><li>意图识别：理解用户问题的根本需求</li><li>上下文：捕捉对话中的历史信息</li><li>情感和歧义处：识别用户情绪以及消除多义词的干扰</li></ul><h3 id="语义技术实现" tabindex="-1">语义技术实现 <a class="header-anchor" href="#语义技术实现" aria-label="Permalink to &quot;语义技术实现&quot;">​</a></h3><ul><li>自然语言处理（NLP）：利用BERT等预训练模型进行分词、句法分析，生成文本向量表示；</li><li>知识图谱：构建实体关系网络（如“产品-故障-解决方案”），支持语义推理；</li><li>深度学习算法：通过LSTM、Transformer模型捕捉长距离语义依赖</li></ul><h2 id="cross-encoder-交叉编码器" tabindex="-1">Cross-Encoder（交叉编码器） <a class="header-anchor" href="#cross-encoder-交叉编码器" aria-label="Permalink to &quot;Cross-Encoder（交叉编码器）&quot;">​</a></h2><p>Cross-Encoder通过联合语义建模和动态交互，解决了传统检索模型的信息丢失与静态表征问题，成为RAG系统中提升精度的关键组件。尽管其计算成本较高，但通过两阶段架构（Bi-Encoder召回+Cross-Encoder精排），可平衡效率与效果。未来，随着模型压缩技术与硬件加速的发展，Cross-Encoder有望在实时场景中发挥更大作用</p><p><strong>1. 联合编码机制</strong></p><p>Cross-Encoder将查询（Query）与文档（Document）拼接为一个整体输入模型（如BERT），通过Transformer层进行双向注意力交互。例如，对查询“机器学习应用”和文档“深度学习在医疗影像中的实践”，模型会同时分析两者所有Token之间的关系，输出一个0-1的相关性分数。</p><p><strong>2. 动态语义建模</strong></p><p>与Bi-Encoder（双编码器）的静态向量不同，Cross-Encoder根据具体查询动态调整文档的语义表征。例如，当查询为“苹果公司市值”时，文档中“苹果手机销量”的权重会被强化，而“苹果水果种植”则被弱化。</p><p><strong>3. 端到端相关性评分</strong></p><p>模型通过分类层直接输出相关性得分，而非通过向量相似度计算。这种端到端的设计能捕捉复杂的语义匹配模式，如逻辑推理、上下文依赖等</p></div></div></main><footer class="VPDocFooter" data-v-f9254922 data-v-3a03286c><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-3a03286c><span class="visually-hidden" id="doc-footer-aria-label" data-v-3a03286c>Pager</span><div class="pager" data-v-3a03286c><!----></div><div class="pager" data-v-3a03286c><a class="VPLink link pager-link next" href="/llm-study/docs/python/1.%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html" data-v-3a03286c><!--[--><span class="desc" data-v-3a03286c>Next page</span><span class="title" data-v-3a03286c>基础知识</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"docs_ai_agents_readme.md\":\"CBRIdwO7\",\"docs_python_1.基础知识.md\":\"DU1EMxie\",\"docs_python_django框架-5.1_基本概念.md\":\"BUdNc-pt\",\"docs_深度学习_readme.md\":\"EsTASKxp\",\"docs_深度学习_sebastian raschka_1.理解大模型.md\":\"Sxw863VH\",\"docs_深度学习_主流大模型原理_deepseek.md\":\"v612l4xq\",\"docs_深度学习_基本概念.md\":\"CBDmzcye\",\"docs_深度学习_李宏毅_2021年_2022年_1.了解线性模型.md\":\"DMySFK1b\",\"docs_深度学习_李宏毅_2021年_2022年_2.机器学习框架.md\":\"DFt5zSjd\",\"docs_深度学习_李宏毅_2023年_2024年_1.chatgpt.md\":\"C1lsTu7H\",\"docs_深度学习_李宏毅_2023年_2024年_2.生成式ai.md\":\"CwmcMwtE\",\"docs_深度学习_李宏毅_2023年_2024年_3.不训练模型__强化模型.md\":\"DtZn0AnH\",\"docs_深度学习_李宏毅_2023年_2024年_4.训练模型步骤.md\":\"CJmMQZv3\",\"docs_深度学习_李宏毅_2023年_2024年_5.transformer.md\":\"DYa_PQr0\",\"docs_深度学习_李宏毅_2023年_2024年_6.评估模型能力_模型的安全性.md\":\"B-SkLoX0\",\"docs_深度学习_李宏毅_2023年_2024年_7.生成策略.md\":\"BEWQm0al\",\"docs_深度学习_李宏毅_2023年_2024年_8.video相关的生成式ai技术.md\":\"CdTS_AJ_\",\"docs_深度学习_李宏毅_readmd.md\":\"CSmrZeEY\",\"docs_知识库_nlp_大模型__问答.md\":\"Dnug9v_J\",\"docs_知识库_rag_ragflow源码分析_knowledge.md\":\"DbqRy_4K\",\"docs_知识库_rag_ragflow源码分析_readme.md\":\"BgLr1okz\",\"docs_知识库_rag_ragflow源码分析_study.md\":\"C4IX3xa7\",\"docs_知识库_rag_ragflow源码分析_文档预处理阶段_(todo)文档解析技术.md\":\"Cjn9atUS\",\"docs_知识库_rag_ragflow源码分析_文档预处理阶段_(todo)构建chunk逻辑详细分析.md\":\"Bg_A3EHq\",\"docs_知识库_rag_ragflow源码分析_文档预处理阶段_文件上传_解析整体流程.md\":\"Dbb57f0Q\",\"docs_知识库_rag_ragflow源码分析_检索阶段_1.向量索引构建.md\":\"m0u5Iv6M\",\"docs_知识库_rag_ragflow源码分析_检索阶段_2.混合检索策略.md\":\"CTWhO-ng\",\"docs_知识库_rag_ragflow源码分析_检索阶段_3.重排序算法.md\":\"CpcQrywk\",\"docs_知识库_rag_ragflow源码分析_生成阶段_生成与交互流程.md\":\"Bl-QvtHs\",\"docs_知识库_rag_readme.md\":\"CwfgFghX\",\"index.md\":\"BhNUKPKk\",\"projects_minirag_readme.md\":\"D-OmG4od\",\"readme.md\":\"Ci1Qkd_X\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"大模型相关学习电子书\",\"description\":\"A VitePress site\",\"base\":\"/llm-study/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"https://github.com/wbccb/llm-study\"}],\"sidebar\":[{\"text\":\"python\",\"items\":[{\"text\":\"基础知识\",\"link\":\"/docs/python/1.基础知识.md\"}]},{\"text\":\"深度学习\",\"items\":[{\"text\":\"基本概念\",\"link\":\"/docs/深度学习/基本概念.md\"},{\"text\":\"DeepSeek\",\"link\":\"/docs/深度学习/主流大模型原理/DeepSeek.md\"}]},{\"text\":\"深度学习-李宏毅\",\"items\":[{\"text\":\"2021年 & 2022年\",\"items\":[{\"text\":\"了解线性模型\",\"link\":\"docs/深度学习/李宏毅/2021年&2022年/1.了解线性模型.md\"},{\"text\":\"机器学习框架\",\"link\":\"docs/深度学习/李宏毅/2021年&2022年/2.机器学习框架.md\"}]},{\"text\":\"2023年&2024年\",\"items\":[{\"text\":\"chatGPT\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/1.chatGPT.md\"},{\"text\":\"生成式AI\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/2.生成式AI.md\"},{\"text\":\"不训练模型=>强化模型\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/3.不训练模型=>强化模型.md\"},{\"text\":\"训练模型步骤\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/4.训练模型步骤.md\"},{\"text\":\"Transformer\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/5.Transformer.md\"},{\"text\":\"评估模型能力&模型的安全性\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/6.评估模型能力&模型的安全性.md\"},{\"text\":\"生成策略\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/7.生成策略.md\"},{\"text\":\"Video相关的生成式AI技术\",\"link\":\"docs/深度学习/李宏毅/2023年&2024年/8.Video相关的生成式AI技术.md\"}]}]},{\"text\":\"知识库\",\"items\":[{\"text\":\"NLP+大模型=>问答\",\"link\":\"docs/知识库/NLP+大模型=>问答.md\"},{\"text\":\"RAGFlow源码分析\",\"items\":[{\"text\":\"文件上传&解析整体流程\",\"link\":\"docs/知识库/RAG/RAGFlow源码分析/文档预处理阶段/文件上传&解析整体流程.md\"}]}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/wbccb\"}]},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>